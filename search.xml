<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[CentOS7.5安装confluence6.15.2]]></title>
    <url>%2Fblogs%2F4100983457.html</url>
    <content type="text"><![CDATA[Confluence简介 Confluence是一个专业的企业知识管理与协同软件，也可以用于构建企业wiki。使用简单，但它强大的编辑和站点管理特征能够帮助团队成员之间共享信息、文档协作、集体讨论，信息推送。 Confluence为团队提供一个协作环境。在这里，团队成员齐心协力，各擅其能，协同地编写文档和管理项目。从此打破不同团队、不同部门以及个人之间信息孤岛的僵局，Confluence真正实现了组织资源共享。 Confluence 已经在超过100个国家，13500个组织中成功地应用于企业内网平台、知识管理及文档管理，涉及财富1000企业、政府机构、教育机构、财务金融机构及技术研究领域。包括IBM、Sun MicroSystems、SAP等众多知名企业使用Confluence来构建企业Wiki并面向公众开放。 准备工作Java环境安装配置 查看JDK软件包列表 yum search java | grep -i --color jdk 选择版本安装 yum install -y java-1.8.0-openjdk java-1.8.0-openjdk-devel 查看JDK是否安装成功 java -version 出现jdk版本信息即安装成功 配置环境变量 在/etc/profile文件添加如下命令 # set java environment JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.181-3.b13.el7_5.x86_64 PATH=$PATH:$JAVA_HOME/bin CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME CLASSPATH PATH 保存关闭profile文件，执行如下命令生效 source /etc/profile 查看JDK变量 echo $JAVA_HOME echo $PATH echo $CLASSPATH mariadb安装 这里依旧使用yum安装，在使用安装命令之前先改下yum的配置文件，走国外镜像下载速度太慢了。 创建MariaDB.repo文件 vim /etc/yum.repos.d/MariaDB.repo 在文件中加入如下代码 [mariadb] name=MariaDB baseurl=http://mirrors.ustc.edu.cn/mariadb/yum/10.3/centos7-amd64/ gpgkey=http://mirrors.ustc.edu.cn/mariadb/yum/RPM-GPG-KEY-MariaDB gpgcheck=1 注意：如果你的文件中已有[mariadb]标签，请直接下该标签下修改对象配置即可。 安装命令 yum -y install mariadb mariadb-server 安装完成MariaDB，首先启动MariaDB，两条命令都可以 systemctl start mariadb 设置开机启动 systemctl enable mariadb 对MariaDB的相关简单配置 mysql_secure_installation 首先是设置密码，会提示先输入密码 Enter current password for root (enter for none):&lt;–初次运行直接回车 设置密码 Set root password? [Y/n] &lt;– 是否设置root用户密码，输入y并回车或直接回车 New password: &lt;– 设置root用户的密码 Re-enter new password: &lt;– 再输入一次你设置的密码 其他配置 Remove anonymous users? [Y/n] &lt;– 是否删除匿名用户，回车 Disallow root login remotely? [Y/n] &lt;–是否禁止root远程登录,回车, Remove test database and access to it? [Y/n] &lt;– 是否删除test数据库，回车 Reload privilege tables now? [Y/n] &lt;– 是否重新加载权限表，回车 初始化MariaDB完成，接下来测试登录 初始化MariaDB完成，接下来测试登录 mysql -uroot -ppassword 配置MariaDB的字符集 文件/etc/my.cnf vim /etc/my.cnf 在[mysqld]标签下添加 [mysqld] init_connect='SET collation_connection = utf8_unicode_ci' init_connect='SET NAMES utf8' character-set-server=utf8 collation-server=utf8_unicode_ci skip-character-set-client-handshake 继续在[mysqld]下设置confluence对应的数据库隔离级别 transaction-isolation = READ-COMMITTED max_allowed_packet = 512M innodb_log_file_size = 2GB 文件/etc/my.cnf.d/client.cnf vim /etc/my.cnf.d/client.cnf 在[client]中添加 default-character-set=utf8 文件/etc/my.cnf.d/mysql-clients.cnf vim /etc/my.cnf.d/mysql-clients.cnf 在[mysql]中添加 default-character-set=utf8 全部配置完成，重启mariadb systemctl restart mariadb 之后进入MariaDB查看字符集 mysql> show variables like "%character%";show variables like "%collation%"; 添加用户，设置权限 创建数据库 create database confluence default character set utf8 collate utf8_bin; 授权 grant all on confluence.* to 'confluence'@'%' identified by 'confluencepasswd'; 即时生效 flush privileges; 这里只开放了confluence用户的内网访问权限，这样访问比较快，也比较安全。如果confluence与mariadb不再同一服务器，需要把localhost换成对应confluence所在的内网ip地址。 Confluence安装 下载安装包 mkdir /mnt/confluence cd /mnt/confluence wget https://downloads.atlassian.com/software/confluence/downloads/atlassian-confluence-6.15.2-x64.bin 给二进制文件授执行权限，然后执行二进制文件进行安装。 chmod +x atlassian-confluence-6.15.2-x64.bin sudo ./atlassian-confluence-6.15.2-x64.bin 安装过程中课自定义部分参数 通过上图可以看出confluence安装到了/opt/atlassian/confluence和/var/atlassian/application-data/confluence目录下。并且confluence默认监听的端口是8090，一路按[Enter]键默认安装即可。 confluence的主要配置文件为/opt/atlassian/confluence/conf/server.xml。此server.xml相当于tomcat中的server.xml配置文件，如果要修改访问端口，可以这里修改。后续如果要配置域名访问也需要到此处配置。 如果要修改confluence的数据目录，可以在安装的时候，在安装过程中进行更换（默认是/var/atlassian/application-data/confluence） 破解安装 下载注册机，以及其他jar包下载地址 从服务器获取atlassian-extras-decoder-v2-3.4.1.jar，命令为atlassian-extras-2.4.jar cd /opt/atlassian/confluence/confluence/WEB-INF/lib/ cp atlassian-extras-decoder-v2-3.4.1.jar /mnt/confluence/atlassian-extras-2.4.jar scp root@*.*.*.*:/mnt/confluence/atlassian-extras-2.4.jar 压缩包下载好之后，解压出来启动confluence_keygen.jar文件 点击.patch，找到刚才传回来的atlassian-extras-2.4.jar文件，点击打开，破解器左下角会提示jar文件破解成功 找到已经破解的jar文件，在文件旁边会有一个atlassian-extras-2.4.jar.bak文件，这是破解器自动备份的，不出问题就不用理会。 上传文件到服务器 #破解文件 scp atlassian-extras-2.4.jar root@*.*.*.*:/mnt/confluence #数据库连接 scp mysql-connector-java-5.1.25-bin.jar root@*.*.*.*:/mnt/confluence #插件破解 scp atlassian-universal-plugin-manager-plugin-3.0.jar root@*.*.*.*:/mnt/confluence # 暂停confluence服务 sudo service confluence stop #将破解文件置入lib包下 cd /opt/atlassian/confluence/confluence/WEB-INF/lib sudo cp /mnt/confluence/atlassian-extras-2.4.jar atlassian-extras-decoder-v2-3.4.1.jar sudo cp /mnt/confluence/mysql-connector-java-5.1.25-bin.jar mysql-connector-java-5.1.25-bin.jar sudo cp /mnt/confluence/atlassian-universal-plugin-manager-plugin-3.0.jar atlassian-universal-plugin-manager-plugin-3.0.jar # 启动confluence服务 sudo service confluence start 选择安装 选择Empty Site 填写授权码 将页面上显示的机器码复制好，打开注册机准备破解。 打开破解机器，输入serverID，确保和网页上显示的服务器ID一致 点击[.gen!]获得授权码。 复制key内的内容，到confluence 设置自己的数据库，正式生产环境直接选择第一项。 输入数据库连接信息 配置admin账号 成功界面 到这里我们的破解安装confluence就已经全部搞定，confluence已经可以愉快的和你一起玩耍了~~ 插件破解 将插件破解jar包丢入lib下后，在插件管理中心安装好插件，点击免费试用，申请license填入框中即可。 后记 如果需要做备份迁移，只要需将原confluence的备份文件导入新的服务器即可 注意：备份还原会替换新服务所有数据，请确保自己知晓愿confluence的管理员账号]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>confluence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用SpringAop记录日志]]></title>
    <url>%2Fblogs%2F104139301.html</url>
    <content type="text"><![CDATA[日志打印 日志作为项目运行中出错的第一手资料，打印的详细与否直接决定了bug解决的快慢。 新建一个注解值记录的bean`javaimport lombok.AllArgsConstructor;import lombok.Data;import lombok.NoArgsConstructor; /** 功能描述： 【注解值bean】* @author chihiro @version V1.0 @date 2019/08/18 14:23*/@Data@NoArgsConstructor@AllArgsConstructorpublic class WebLogValue { public String value; public String name; } - 输出日志 ```java /** * 功能描述： * 【接口入出参日志打印】 * * @author chihiro * @version V1.0 * @date 2019/08/18 01:06 */ @Aspect @Order(99) @Component @Slf4j public class WebLogAspect { /** * Controller层切点 使用到了spring原生的RequestMapping 作为切点表达式。 */ @Pointcut(&quot;@annotation(org.springframework.web.bind.annotation.RequestMapping)&quot;) public void webLog() { } @Before(&quot;webLog()&quot;) public void doBefore(JoinPoint joinPoint) { try { StringBuilder params = new StringBuilder(); Object[] args = joinPoint.getArgs(); for (int i = 0; i &lt; args.length; i++) { Object object = args[i]; // 此处过滤掉一些无需打印的参数 if (object instanceof MultipartFile || object instanceof HttpServletRequest || object instanceof HttpServletResponse) { continue; } params.append(JSON.toJSONString(object)); if (i &lt; args.length - 1) { params.append(&quot;,&quot;); } } log.info(&quot;类信息[{}],请求参数[{}]&quot;, getRequestMappingAnnotationValue(joinPoint), params.toString()); } catch (Exception e) { //记录本地异常日志 log.error(&quot;===前置Controller通知异常===&quot;); log.error(&quot;异常信息:{}&quot;, e.getMessage()); } } @AfterReturning(returning = &quot;response&quot;, pointcut = &quot;webLog()&quot;) public void doAfterReturning(JoinPoint joinPoint, Object response) throws Throwable { HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); if (response != null) { try { log.info(&quot;类信息[{}],请求地址[{}],返回参数[{}]&quot;, getRequestMappingAnnotationValue(joinPoint), request.getRemoteAddr(), JSON.toJSONString(response)); } catch (Exception e) { //记录本地异常日志 log.error(&quot;===后置Controller通知异常===&quot;); log.error(&quot;异常信息:{}&quot;, e.getMessage()); } } } /** * 获取RequestMapping中注解值 */ private static WebLogValue getRequestMappingAnnotationValue(JoinPoint joinPoint) throws Exception { String targetName = joinPoint.getTarget().getClass().getName(); String methodName = joinPoint.getSignature().getName(); Object[] arguments = joinPoint.getArgs(); Class targetClass = Class.forName(targetName); Method[] methods = targetClass.getMethods(); WebLogValue webLogValue = new WebLogValue(); for (Method method : methods) { if (method.getName().equals(methodName)) { Class[] parameterTypes = method.getParameterTypes(); if (parameterTypes.length == arguments.length) { String[] value = method.getAnnotation(RequestMapping.class).value(); String name = method.getAnnotation(RequestMapping.class).name(); webLogValue.setValue(Arrays.toString(value)); webLogValue.setName(name); break; } } } return webLogValue; } 日志入库 日志表的DDL信息CREATE TABLE `pm_log` ( `log_id` varchar(32) NOT NULL COMMENT '主键id', `user_name` varchar(50) DEFAULT NULL COMMENT '用户名', `ip` varchar(20) DEFAULT NULL COMMENT 'ip信息', `params` varchar(255) DEFAULT NULL COMMENT '请求参数', `result` longtext COMMENT '返回结果', `method` varchar(150) DEFAULT NULL COMMENT '方法名', `operation` varchar(50) DEFAULT NULL COMMENT '操作', `unique_code` varchar(20) DEFAULT NULL COMMENT '唯一标识', `error` char(2) DEFAULT NULL COMMENT '是否异常00：异常，01：正常', `stack` longtext COMMENT '异常堆栈', `take_time` bigint(20) DEFAULT NULL COMMENT '请求耗时', `create_time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间', PRIMARY KEY (`log_id`) USING BTREE, KEY `unique_code` (`unique_code`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC; 此处数据库设计未经详细考虑，有更好想法的朋友欢迎留言讨论。 核心代码`java/** 功能描述： 【操作日志记录切面】* @author chihiro @version V1.0 @date 2019/08/18 01:06*/@Aspect@Order(100)@Component@Slf4jpublic class SysLoggerAspect { @Autowiredprivate LogRecordHandler logRecordHandler; @Pointcut(“@annotation(org.springframework.web.bind.annotation.RequestMapping)”)public void sysLogger() {} @Before(“sysLogger()”)public void doBeforeController(JoinPoint joinPoint) { // 开始时间 long startTime = System.currentTimeMillis(); ThreadLocalUtil.setValue(KeyConstants.START_TIME.getKey(), String.valueOf(startTime)); MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); SysLog sysLog = new SysLog(); RequestMapping requestMapping = method.getAnnotation(RequestMapping.class); if (requestMapping != null) { //注解上的描述 sysLog.setOperation(requestMapping.name()); } //请求的方法名 String className = joinPoint.getTarget().getClass().getName(); String methodName = signature.getName(); sysLog.setMethod(className + &quot;.&quot; + methodName + &quot;()&quot;); //请求的参数 Object[] args = joinPoint.getArgs(); StringBuilder sbParams = new StringBuilder(); for (int i = 0; i &lt; args.length; i++) { Object object = args[i]; if (object instanceof MultipartFile || object instanceof HttpServletRequest || object instanceof HttpServletResponse) { continue; } sbParams.append(JSON.toJSONString(object)); if (i &lt; args.length - 1) { sbParams.append(&quot;,&quot;); } } String params = sbParams.toString(); if (StrUtil.isNotBlank(params)) { sysLog.setParams(params); } //请求的用户 String userName = ThreadLocalUtil.getValue(KeyConstants.USER_NAME.getKey()); if (StrUtil.isNotBlank(userName)) { sysLog.setUserName(userName); } //用户的IP sysLog.setIp(WebUtil.getIpAddress()); // 设置唯一标识 sysLog.setUniqueCode(ThreadLocalUtil.getValue(KeyConstants.UNIQUE_CODE.getKey())); ThreadLocalUtil.setValue(KeyConstants.SYS_LOG.getKey(), JSON.toJSONString(sysLog)); // logRecordHandler.recordLog(sysLog);} @AfterReturning(value = “sysLogger()”, returning = “res”)public void doAfterReturning(JoinPoint joinPoint, Object res) { long takeTime = System.currentTimeMillis() - Long.valueOf(ThreadLocalUtil.getValue(KeyConstants.START_TIME.getKey())); SysLog sysLog = new SysLog(); SysLog sys = JSON.parseObject(ThreadLocalUtil.getValue(KeyConstants.SYS_LOG.getKey()), SysLog.class); BeanUtil.copyProperties(sys, sysLog); // 设置返回结果 sysLog.setResult(JSON.toJSONString(res)); // 设置请求耗时 sysLog.setTakeTime(takeTime); sysLog.setError(&quot;01&quot;); ThreadLocalUtil.removeValue(KeyConstants.START_TIME.getKey()); ThreadLocalUtil.removeValue(KeyConstants.SYS_LOG.getKey()); // 发送MQ消息 logRecordHandler.recordLog(sysLog); } @AfterThrowing(value = “sysLogger()”, throwing = “throwable”)public void doAfterThrowing(JoinPoint joinPoint, Throwable throwable) { long takeTime = System.currentTimeMillis() - Long.valueOf(ThreadLocalUtil.getValue(KeyConstants.START_TIME.getKey())); SysLog sysLog = new SysLog(); SysLog sys = JSON.parseObject(ThreadLocalUtil.getValue(KeyConstants.SYS_LOG.getKey()), SysLog.class); BeanUtil.copyProperties(sys, sysLog); // 设置请求耗时 sysLog.setTakeTime(takeTime); // 设置堆栈信息 sysLog.setStack(Arrays.toString(throwable.getStackTrace())); sysLog.setError(&quot;00&quot;); ThreadLocalUtil.removeValue(KeyConstants.START_TIME.getKey()); ThreadLocalUtil.removeValue(KeyConstants.SYS_LOG.getKey()); // 发送MQ消息 logRecordHandler.recordLog(sysLog); } } - 日志实体 ```java /** * 功能描述： * 【日志实体】 * * @author chihiro * @version V1.0 * @date 2019/08/18 01:59 */ @Data @NoArgsConstructor @AllArgsConstructor public class SysLog implements Serializable { private static final long serialVersionUID = 5L; /** * 主键id */ private String logId; /** * 用户名 */ private String userName; /** * 用户操作 */ private String operation; /** * 请求方法 */ private String method; /** * 请求参数 */ private String params; /** * 请求结果 */ private String result; /** * IP地址 */ private String ip; /** * 唯一标识 */ private String uniqueCode; /** * 是否异常 * 00：异常 * 01：正常 */ private String error; /** * 异常堆栈 */ private String stack; /** * 请求耗时 */ private Long takeTime; /** * 创建时间 */ @JsonFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;, timezone = &quot;GMT+8&quot;) private LocalDateTime createTime; } key枚举 /** * 功能描述： * 【项目key枚举】 * * @author chihiro * @version V1.0 * @date 2019/09/04 11:33 */ public enum KeyConstants { // 用户编号记录 USER_ID("userId"), // 用户名记录 USER_NAME("username"), // 用户所属唯一标识 UNIQUE_CODE("uniqueCode"), // 请求开始时间 START_TIME("startTime"), // 日志对象 SYS_LOG("sysLog"); private String key; public String getKey() { return key; } KeyConstants(String key) { this.key = key; } } MQ处理器`java/** 功能描述： 【日志记录处理器】* @author chihiro @version V1.0 @date 2019/09/04 11:07*/@Component@Slf4jpublic class LogRecordHandler { @Autowiredprivate AmqpTemplate rabbitTemplate; /** 将操作日记发往MQ处理* @param sysLog 日志实体*/public void recordLog(SysLog sysLog) { rabbitTemplate.convertAndSend(MqConstants.QUEUE_LOG_RECODE.getTopic(), JSON.toJSONString(sysLog));} } - 本地线程工具类 ```java /** * 本地线程工具类 * * @author chihiro * @version V1.0 * @date 2019/09/04 11:10 */ public final class ThreadLocalUtil { private static final ThreadLocal&lt;Map&lt;String, String&gt;&gt; THREAD_CONTEXT = ThreadLocal.withInitial(HashMap::new); /** * 根据key获取值 * * @param key 键值 * @return value */ public static String getValue(String key) { if (THREAD_CONTEXT.get() == null) { return null; } return THREAD_CONTEXT.get().get(key); } /** * 存储 * * @param key 键值 * @param value 值 */ public static String setValue(String key, String value) { Map&lt;String, String&gt; cacheMap = THREAD_CONTEXT.get(); if (cacheMap == null) { cacheMap = new HashMap&lt;&gt;(); THREAD_CONTEXT.set(cacheMap); } return cacheMap.put(key, value); } /** * 根据key移除值 * * @param key 键值 */ public static void removeValue(String key) { Map&lt;String, String&gt; cacheMap = THREAD_CONTEXT.get(); if (cacheMap != null) { cacheMap.remove(key); } } /** * 重置 */ public static void reset() { if (THREAD_CONTEXT.get() != null) { THREAD_CONTEXT.get().clear(); } } } http工具类`java/** 功能描述： 【Http工具类】* @author chihiro @version V1.0 @date 2019/09/04 11:58*/public class WebUtil { public static Map&lt;String, String&gt; queryStringToMap(String queryString, String charset) { try { Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); String[] decode = URLDecoder.decode(queryString, charset).split(&quot;&amp;&quot;); for (String keyValue : decode) { String[] kv = keyValue.split(&quot;[=]&quot;, 2); map.put(kv[0], kv.length &gt; 1 ? kv[1] : &quot;&quot;); } return map; } catch (UnsupportedEncodingException e) { throw new UnsupportedOperationException(e); } } /** 尝试获取当前请求的HttpServletRequest实例* @return HttpServletRequest*/public static HttpServletRequest getHttpServletRequest() { try { return ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest(); } catch (Exception e) { return null; }} public static Map&lt;String, String&gt; getParameters(HttpServletRequest request) { Map&lt;String, String&gt; parameters = new HashMap&lt;&gt;(); Enumeration enumeration = request.getParameterNames(); while (enumeration.hasMoreElements()) { String name = String.valueOf(enumeration.nextElement()); parameters.put(name, request.getParameter(name)); } return parameters; } public static Map&lt;String, String&gt; getHeaders(HttpServletRequest request) { Map&lt;String, String&gt; map = new LinkedHashMap&lt;&gt;(); Enumeration&lt;String&gt; enumeration = request.getHeaderNames(); while (enumeration.hasMoreElements()) { String key = enumeration.nextElement(); String value = request.getHeader(key); map.put(key, value); } return map; } private static final String[] IP_HEADERS = { &quot;X-Forwarded-For&quot;, &quot;X-Real-IP&quot;, &quot;Proxy-Client-IP&quot;, &quot;WL-Proxy-Client-IP&quot; }; /** 获取请求客户端的真实ip地址* @param request 请求对象 @return ip地址*/public static String getIpAddress(HttpServletRequest request) { // 获取请求主机IP地址,如果通过代理进来，则透过防火墙获取真实IP地址 String ip = request.getHeader(IP_HEADERS[0]); if (ip == null || ip.length() == 0 || “unknown”.equalsIgnoreCase(ip)) { if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) { ip = request.getHeader(&quot;Proxy-Client-IP&quot;); } if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) { ip = request.getHeader(&quot;WL-Proxy-Client-IP&quot;); } if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) { ip = request.getHeader(&quot;HTTP_CLIENT_IP&quot;); } if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) { ip = request.getHeader(&quot;HTTP_X_FORWARDED_FOR&quot;); } if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) { ip = request.getRemoteAddr(); } } else if (ip.length() &gt; 15) { String[] ips = ip.split(&quot;,&quot;); for (int index = 0; index &lt; ips.length; index++) { String strIp = (String) ips[index]; if (!(&quot;unknown&quot;.equalsIgnoreCase(strIp))) { ip = strIp; break; } } } return ip;} /** 获取请求客户端的真实ip地址* @return ip地址*/public static String getIpAddress() { // 获取请求主机IP地址,如果通过代理进来，则透过防火墙获取真实IP地址 return getIpAddress(getHttpServletRequest());} /** web应用绝对路径* @param request 请求对象 @return 绝对路径*/public static String getBasePath(HttpServletRequest request) { String path = request.getContextPath(); return request.getScheme() + “://“ + request.getServerName() + “:” + request.getServerPort() + path + “/“;} }` 以上，代码展示完毕，日志的入库使用MQ进行异步。经测试，功能无误，尚未上线测试，未知性能问题。后记 MQ的使用可参考这篇文章 欢迎指正博客内不足之处]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>aop</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java操作rabbitmq示例]]></title>
    <url>%2Fblogs%2F1451877531.html</url>
    <content type="text"><![CDATA[关于Java中多级菜单树的处理前言 此 demo 主要演示了 Spring Boot 如何集成 RabbitMQ，并且演示了基于直接队列模式、分列模式、主题模式的消息发送和接收。 正文 关于如何搭建rabbitmq，请查看[这篇文章][https://chihiro.org.cn/blogs/18208907.html] pom文件示例&lt;?xml version="1.0" encoding="UTF-8"?> &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"> &lt;modelVersion>4.0.0&lt;/modelVersion> &lt;artifactId>spring-boot-demo-mq-rabbitmq&lt;/artifactId> &lt;version>1.0.0-SNAPSHOT&lt;/version> &lt;packaging>jar&lt;/packaging> &lt;name>spring-boot-demo-mq-rabbitmq&lt;/name> &lt;description>Demo project for Spring Boot&lt;/description> &lt;parent> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-parent&lt;/artifactId> &lt;version>2.1.4.RELEASE&lt;/version> &lt;relativePath/> &lt;!-- lookup parent from repository --> &lt;/parent> &lt;properties> &lt;project.build.sourceEncoding>UTF-8&lt;/project.build.sourceEncoding> &lt;project.reporting.outputEncoding>UTF-8&lt;/project.reporting.outputEncoding> &lt;java.version>1.8&lt;/java.version> &lt;/properties> &lt;dependencies> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-web&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-amqp&lt;/artifactId> &lt;/dependency> &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;dependency> &lt;groupId>org.projectlombok&lt;/groupId> &lt;artifactId>lombok&lt;/artifactId> &lt;optional>true&lt;/optional> &lt;version>1.16.20&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>cn.hutool&lt;/groupId> &lt;artifactId>hutool-all&lt;/artifactId> &lt;version>4.6.3&lt;/version> &lt;/dependency> &lt;dependency> &lt;groupId>com.google.guava&lt;/groupId> &lt;artifactId>guava&lt;/artifactId> &lt;version>28.1-jre&lt;/version> &lt;/dependency> &lt;/dependencies> &lt;build> &lt;finalName>spring-boot-demo-mq-rabbitmq&lt;/finalName> &lt;plugins> &lt;plugin> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-maven-plugin&lt;/artifactId> &lt;/plugin> &lt;/plugins> &lt;/build> &lt;/project> application.ymlserver: port: 8080 servlet: context-path: /demo spring: rabbitmq: host: localhost port: 5672 username: guest password: guest virtual-host: / # 手动提交消息 listener: simple: acknowledge-mode: manual direct: acknowledge-mode: manual RabbitConsts.javapackage cloud.pm.log.common.context; /** * 功能描述： * 【RabbitMQ常量池】 * * @author chihiro * @version V1.0 * @date 2019/09/03 19:56 */ public class RabbitConstants { /** * 分列模式 */ public final static String FANOUT_MODE_QUEUE = "fanout.mode"; /** * 日志打印队列 */ public final static String QUEUE_LOG_PRINT = "queue.log.recode"; /** * 主题模式 */ public final static String TOPIC_MODE_QUEUE = "topic.mode"; /** * 主题模式 */ public final static String TOPIC_ROUTING_KEY = "topic.*"; } RabbitMqConfig.javapackage cloud.pm.log.common.config; import cloud.pm.log.common.context.RabbitConstants; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.core.*; import org.springframework.amqp.rabbit.connection.CachingConnectionFactory; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * 功能描述： * 【RabbitMQ配置，主要是配置队列，如果提前存在该队列，可以省略本配置类】 * * @author chihiro * @version V1.0 * @date 2019/09/03 19:58 */ @Slf4j @Configuration public class RabbitMqConfig { @Bean public RabbitTemplate rabbitTemplate(CachingConnectionFactory connectionFactory) { connectionFactory.setPublisherConfirms(true); connectionFactory.setPublisherReturns(true); RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); rabbitTemplate.setMandatory(true); rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -> log.info("消息发送成功:correlationData[{}],ack[{}],cause[{}]", correlationData, ack, cause)); rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey) -> log.info("消息丢失:exchange[{}],route[{}],replyCode[{}],replyText[{}],message:{}", exchange, routingKey, replyCode, replyText, message)); return rabbitTemplate; } /** * 日志打印队列 */ @Bean public Queue logPrintQueue() { return new Queue(RabbitConstants.QUEUE_LOG_PRINT); } /** * 分列模式队列 */ @Bean public FanoutExchange fanoutExchange() { return new FanoutExchange(RabbitConstants.FANOUT_MODE_QUEUE); } /** * 分列模式绑定队列 * * @param logPrintQueue 绑定队列 * @param fanoutExchange 分列模式交换器 */ @Bean public Binding fanoutBinding(Queue logPrintQueue, FanoutExchange fanoutExchange) { return BindingBuilder.bind(logPrintQueue).to(fanoutExchange); } /** * 主题队列 */ @Bean public Queue topicQueue() { return new Queue(RabbitConstants.TOPIC_ROUTING_KEY); } /** * 主题模式队列 * &lt;li>路由格式必须以 . 分隔，比如 user.email 或者 user.aaa.email&lt;/li> * &lt;li>通配符 * ，代表一个占位符，或者说一个单词，比如路由为 user.*，那么 user.email 可以匹配，但是 user.aaa.email 就匹配不了&lt;/li> * &lt;li>通配符 # ，代表一个或多个占位符，或者说一个或多个单词，比如路由为 user.#，那么 user.email 可以匹配，user.aaa.email 也可以匹配&lt;/li> */ @Bean public TopicExchange topicExchange() { return new TopicExchange(RabbitConstants.TOPIC_MODE_QUEUE); } /** * 主题模式绑定队列2 * * @param topicQueue 主题队列 * @param topicExchange 主题模式交换器 */ @Bean public Binding topicBinding(Queue topicQueue, TopicExchange topicExchange) { return BindingBuilder.bind(topicQueue).to(topicExchange).with(RabbitConstants.TOPIC_ROUTING_KEY); } } RabbitMqHandler.javapackage cloud.pm.log.handler; import cloud.pm.log.common.context.RabbitConstants; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.rabbit.annotation.RabbitListener; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Component; /** * 功能描述： * 【消息队列处理器】 * * @author chihiro * @version V1.0 * @date 2019/09/03 20:22 */ @Slf4j @Component public class RabbitMqHandler { /** * 日志打印处理handler * * @param message 待处理的消息体 */ @RabbitListener(queues = RabbitConstants.QUEUE_LOG_PRINT) public void queueLogPrintHandler(String message) { log.info("接收到操作日志记录消息：[{}]", message); } /** * 主题模式处理handler * * @param message 待处理的消息体 */ @RabbitListener(queues = RabbitConstants.TOPIC_ROUTING_KEY) public void queueTopicHandler(String message) { log.info("主题模式处理器，接收消息：[{}]", message); } } RabbitMqTests.javapackage cloud.pm.log; import cloud.pm.log.common.context.RabbitConstants; import lombok.extern.slf4j.Slf4j; import org.junit.Test; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.beans.factory.annotation.Autowired; /** * 功能描述： * 【消息队列测试】 * * @author chihiro * @version V1.0 * @date 2019/09/03 20:15 */ @RunWith(SpringRunner.class) @SpringBootTest @Slf4j public class RabbitMqTests { @Autowired private RabbitTemplate rabbitTemplate; /** * 测试直接模式发送 */ @Test public void sendDirect() { String message = "direct message"; rabbitTemplate.convertAndSend(RabbitConstants.QUEUE_LOG_PRINT, message); log.info("消息发送成功：[{}]", message); } /** * 测试主题模式发送 */ @Test public void sendTopic() { String message = "topic message"; rabbitTemplate.convertAndSend(RabbitConstants.TOPIC_MODE_QUEUE, "topic.queue", message); log.info("消息发送成功：[{}]", message); } } 以上示例代码编写完毕 后记 这套代码是博主从网上找来调整为自己使用的，非博主独立构建。 若遇到其他Bug，请通过博客内联系方式找博主修复。]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>rabbitmq</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下rabbitMQ安装]]></title>
    <url>%2Fblogs%2F18208907.html</url>
    <content type="text"><![CDATA[安装依赖 RabbitMQ依赖Erlang，需要先安装Erlang。 #启动EPEL源 sudo yum install epel-release 安装erlang sudo yum install erlang 下载并解压安装包 先新建一个文件夹，博主喜欢在/var下面安装服务器软件 cd /var mkdir rabbitmq cd rabbitmq 下载rpm wget https://www.rabbitmq.com/releases/rabbitmq-server/v3.6.15/rabbitmq-server-3.6.15-1.el6.noarch.rpm 下载完成后安装 yum install rabbitmq-server-3.6.15-1.el6.noarch.rpm RabbitMQ的一些基本操作# 添加开机启动RabbitMQ服务 sudo chkconfig rabbitmq-server on # 启动服务 sudo /sbin/service rabbitmq-server start # 查看服务状态 sudo /sbin/service rabbitmq-server status # 停止服务 sudo /sbin/service rabbitmq-server stop # 查看当前所有用户 sudo rabbitmqctl list_users # 查看默认guest用户的权限 sudo rabbitmqctl list_user_permissions guest # 由于RabbitMQ默认的账号用户名和密码都是guest。为了安全起见, 先删掉默认用户 sudo rabbitmqctl delete_user guest # 添加新用户 sudo rabbitmqctl add_user username password # 设置用户tag sudo rabbitmqctl set_user_tags username administrator # 赋予用户默认vhost的全部操作权限 sudo rabbitmqctl set_permissions -p / username ".*" ".*" ".*" # 查看用户的权限 sudo rabbitmqctl list_user_permissions username 更多关于rabbitmqctl的使用，可以参考帮助手册。 开启web管理接口 RabbitMQ自带了web管理界面，只需要启动插件便可以使用。 sudo rabbitmq-plugins enable rabbitmq_management 然后通过浏览器访问 http://yourhost:15672 配置RabbitMQ 关于每个配置项的具体作用，可以参考官方文档。更新配置后，别忘了重启服务哦！ 开启用户远程访问 默认情况下，RabbitMQ的默认的guest用户只允许本机访问， 如果想让guest用户能够远程访问的话，只需要将配置文件中的loopback_users列表置为空即可，如下： {loopback_users, []} 另外关于新添加的用户，直接就可以从远程访问的，如果想让新添加的用户只能本地访问，可以将用户名添加到上面的列表, 如只允许admin用户本机访问。 {loopback_users, ["admin"]} 更新配置后，需要重启服务 sudo /sbin/service rabbitmq-server status # 查看服务状态 进入log文件夹内查看日志 cd /var/log/rabbitmq 这里显示的是没有找到配置文件，我们可以自己创建这个文件 cd /etc/rabbitmq/ vim rabbitmq.config 编辑内容如下： [{rabbit, [{loopback_users, []}]}]. 这里的意思是开放使用，rabbitmq默认创建的用户guest，密码也是guest，这个用户默认只能是本机访问，localhost或者127.0.0.1，从外部访问需要添加上面的配置。 保存配置后重启服务： service rabbitmq-server stop service rabbitmq-server start 此时就可以从外部访问了，至此rabbitmq已经搭建完成，去做测试吧WwW 后记记得要开放5672和15672端口 5672表示客户端访问端口 15672表示web界面展示接口]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>rabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache Archiva 私服搭建]]></title>
    <url>%2Fblogs%2F1040711240.html</url>
    <content type="text"><![CDATA[下载安装程序 进入 Archiva 的项目的下载页面中，请单击链接来下载你需要的版本。 在这里我们选择下在 tar.gz 的版本。 你可以在这里拷贝下载链接，然后在 CentOS 上使用 wget，你也可以下载 tar.gz 文件后，上传到你的服务器上。 博主使用 wget 直接下载到你的服务器上。 对tar包进行解压缩，在 CentOS 上，你可以使用下面的命令来进行解压缩： tar -xzvf apache-archiva-2.2.3-bin.tar.gz 解压缩的文件名称为 apache-archiva-2.2.3 在 /var下面新建一个archiva 文件夹 使用命令，将解压缩后的文件夹移动到 /var/archiva 文件夹下 mv apache-archiva-2.2.3 /var/archiva 运行 archiva 在/var/archiva/conf目录下编辑jetty.xml &lt;Call name="addConnector"> &lt;Arg> &lt;New class="org.eclipse.jetty.server.nio.SelectChannelConnector"> &lt;Set name="host">&lt;SystemProperty name="jetty.host"/>&lt;/Set> &lt;Set name="port">&lt;SystemProperty name="jetty.port" default="8080"/>&lt;/Set> &lt;Set name="maxIdleTime">30000&lt;/Set> &lt;Set name="Acceptors">2&lt;/Set> &lt;Set name="statsOn">false&lt;/Set> &lt;Set name="confidentialPort">8443&lt;/Set> &lt;Set name="lowResourcesConnections">5000&lt;/Set> &lt;Set name="lowResourcesMaxIdleTime">5000&lt;/Set> &lt;/New> &lt;/Arg> &lt;/Call> 将8080改为你想要的端口即可。 在 /var/archiva 路径下，运行命令： ./bin/archiva start 使用命令查看是否启动成功 ps -ef |grep archiva 确认是否安装成功 如果你能够通过给定的 UI 和端口看到管理员的 Web 界面的话，那么就表示你的安装已经成功了。 进入页面后可在右上角创建一个新的用户，之后要使用这个用户来继续上传下载jar包。 将 archiva 在 CentOS 中安装成服务 在 Linux环境下，archiva 安装目录下的 bin/archiva 是直接启动的，你可以为你的 CentOS 创建一个启动 link 到这个文件中，你也可以知己拷贝这个文件到 /etc/init.d 目录下，然后通过 root 来进行运行。但是在我们测试后，发现直接将 archiva 拷贝到 /etc/init.d 中是无法启动的，所以你最好是创建一个链接。 针对上面的完全的安装后，创建链接的命令为： ln -sf /opt/archiva/bin/archiva /etc/init.d/archiva 然后你就可以通过以下命令来启动个关闭archiva服务了 #开启服务 service archiva start #关闭服务 service archiva stop 配置私服仓库 访问你私服的地址页面，使用用户名进行登陆。 配置仓库地址 在页面上的【Directory】位置配置自己的仓库文件储存位置。 下面的【Snapshots】选项可以勾上，表示自己存储库支持快照工作 在如下位置记录了你的仓库地址： 在这里新增一个名为maven-public组，将右边三个仓库全部添加进去。 这里你需要几个仓库就配置几个仓库，有几个仓库这边就会显示几个仓库组。右边的仓库地址后续配置用得到。 settings.xml文件配置 &lt;!-- 本地仓库--> &lt;localRepository>D:\WorkJarSource-Apache\repository&lt;/localRepository> &lt;!-- 插件库 --> &lt;pluginGroups> &lt;pluginGroup>org.mortbay.jetty&lt;/pluginGroup> &lt;/pluginGroups> &lt;!-- 服务器配置 --> &lt;servers> &lt;server> &lt;id>releases&lt;/id> &lt;username>username&lt;/username> &lt;password>password&lt;/password> &lt;/server> &lt;server> &lt;id>snapshots&lt;/id> &lt;username>username&lt;/username> &lt;password>password&lt;/password> &lt;/server> &lt;/servers> &lt;!-- 镜像配置 --> &lt;mirrors> &lt;mirror> &lt;id>public&lt;/id> &lt;!-- 自己的仓库地址 --> &lt;url>http://12.12.123.123:8080/repository/maven-public/&lt;/url> &lt;mirrorOf>*&lt;/mirrorOf> &lt;/mirror> &lt;/mirrors> &lt;profiles> &lt;profile> &lt;activation> &lt;activeByDefault>true&lt;/activeByDefault> &lt;/activation> &lt;repositories> &lt;repository> &lt;id>public&lt;/id> &lt;name>Archiva Managed Internal Repository&lt;/name> &lt;url>http://12.12.123.123:8080/repository/maven-public/&lt;/url> &lt;releases> &lt;enabled>true&lt;/enabled> &lt;/releases> &lt;snapshots> &lt;enabled>true&lt;/enabled> &lt;/snapshots> &lt;/repository> &lt;repository> &lt;id>central&lt;/id> &lt;name>Archiva Managed central Repository&lt;/name> &lt;url>http://central&lt;/url> &lt;releases> &lt;enabled>true&lt;/enabled> &lt;/releases> &lt;snapshots> &lt;enabled>true&lt;/enabled> &lt;/snapshots> &lt;/repository> &lt;/repositories> &lt;/profile> &lt;/profiles> 上述配置文件只是部分配置，可以在此基础上进行添加。 jar包上传 按照图示填入对象的jar包或者pom文件信息 选择文件后点击按钮【Start Upload】，之后点击【Save Files】 成功上传。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>Archiva</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RBAC用户权限管理数据库设计]]></title>
    <url>%2Fblogs%2F2455283662.html</url>
    <content type="text"><![CDATA[设计过程前几天下来一个需求，需要博主基于现有的业务系统体系内，重构一套RBAC的访问控制系统。功能不用太多，有最基本的权限控制就可以。 RBAC（Role-Based Access Control，基于角色的访问控制），就是用户通过角色与权限进行关联。简单地说，一个用户拥有若干角色，每一个角色拥有若干权限。这样，就构造成“用户-角色-权限”的授权模型。在这种模型中，用户与角色之间，角色与权限之间，一般者是多对多的关系。（如下图） 角色是什么？可以理解为一定数量的权限的集合，权限的载体。例如：一个论坛系统，“超级管理员”、“版主”都是角色。版主可管理版内的帖子、可管理版内的用户等，这些是权限。要给某个用户授予这些权限，不需要直接将权限授予用户，可将“版主”这个角色赋予该用户。 当用户的数量非常大时，要给系统每个用户逐一授权（授角色），是件非常烦琐的事情。这时，就需要给用户分组，每个用户组内有多个用户。除了可给用户授权外，还可以给用户组授权。这样一来，用户拥有的所有权限，就是用户个人拥有的权限与该用户所在用户组拥有的权限之和。（下图为用户组、用户与角色三者的关联关系） 在应用系统中，权限表现成什么？对功能模块的操作，对上传文件的删改，菜单的访问，甚至页面上某个按钮、某个图片的可见性控制，都可属于权限的范畴。有些权限设计，会把功能操作作为一类，而把文件、菜单、页面元素等作为另一类，这样构成“用户-角色-权限-资源”的授权模型。而在做数据表建模时，可把功能操作和资源统一管理，也就是都直接与权限表进行关联，这样可能更具便捷性和易扩展性。（见下图） 请留意权限表中有一列“权限类型”，我们根据它的取值来区分是哪一类权限，如“MENU”表示菜单的访问权限、“OPERATION”表示功能模块的操作权限、“FILE”表示文件的修改权限、“ELEMENT”表示页面元素的可见性控制等。 这样设计的好处有二。其一，不需要区分哪些是权限操作，哪些是资源，（实际上，有时候也不好区分，如菜单，把它理解为资源呢还是功能模块权限呢？）。其二，方便扩展，当系统要对新的东西进行权限控制时，我只需要建立一个新的关联表“权限XX关联表”，并确定这类权限的权限类型字符串。 这里要注意的是，权限表与权限菜单关联表、权限菜单关联表与菜单表都是一对一的关系。（文件、页面权限点、功能操作等同理）。也就是每添加一个菜单，就得同时往这三个表中各插入一条记录。这样，可以不需要权限菜单关联表，让权限表与菜单表直接关联，此时，须在权限表中新增一列用来保存菜单的ID，权限表通过“权限类型”和这个ID来区分是种类型下的哪条记录。 到这里，RBAC权限模型的扩展模型的完整设计图如下： 随着系统的日益庞大，为了方便管理，可引入角色组对角色进行分类管理，跟用户组不同，角色组不参与授权。例如：某电网系统的权限管理模块中，角色就是挂在区局下，而区局在这里可当作角色组，它不参于权限分配。另外，为方便上面各主表自身的管理与查找，可采用树型结构，如菜单树、功能树等，当然这些可不需要参于权限分配。 简单设计： 后记原文来自：点我啦点我啦，感谢这位大哥的方案，博主红着脸拿过来copy了一份。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>RBAC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下haproxy安装]]></title>
    <url>%2Fblogs%2F4248711648.html</url>
    <content type="text"><![CDATA[安装依赖包 haproxy部署安装对环境有要求，一键安装以下依赖即可。 yum -y install wget gcc gcc-c++ 下载并解压安装包 先新建一个文件夹，博主喜欢在/var下面安装服务器软件 cd /var mkdir haproxy cd haproxy 下载tar包并解压缩 wget https://github.com/haproxy/haproxy/archive/v1.5-dev20.tar.gz &amp;&amp; tar -zvxf v1.5-dev20.tar.gz cd haproxy-1.5-dev20 安装nginx 查看内核版本 uname -a 如图所示内核版本为3.10开头，执行下列编译命令： make TARGET=linux310 ARCH=x86_64 PREFIX=/usr/local/haproxy make install PREFIX=/usr/local/haproxy 这里可能会报错cannot bind UNIX socket [/var/lib/haproxy/stats]解决方案：mkdir -p /var/lib/haproxy &amp;&amp; touch /var/lib/haproxy/stats 配置haproxy.conf 进入编译后的haproxy文件夹 cd /usr/local/haproxy 新建conf目录，并新建一个配置文件 mkdir conf touch /usr/local/haproxyconf/haproxy.conf 编辑配置文件 vim /usr/local/haproxyconf/haproxy.conf 这里配置从简，制作最基本的配置。 global log 127.0.0.1 local2 #[err warning info debug] chroot /usr/local/haproxy pidfile /var/run/haproxy.pid #haproxy的pid存放路径,启动进程的用户必须有权限访问此文件 maxconn 65535 #最大连接数，默认4000 daemon #后台启动 defaults mode tcp log global timeout connect 20s timeout server 60s timeout client 60s retries 3 listen stats mode http bind 0.0.0.0:8989 #监听端口 stats refresh 10s #统计页面自动刷新时间 stats uri /stats #统计页面url stats realm Haproxy Manager #统计页面密码框上提示文本 stats auth chihiro:chihiroadmin #统计页面用户名和密码设置 stats hide-version #隐藏统计页面上HAProxy的版本信息 listen chihirov1 bind :8901 #监听端口 server s1 xxx.xxx.xxx.xxx:1234 #转发IP+端口 listen chihirov2 bind :8902 #监听端口 server s2 xxx.xxx.xxx.xxx:5678 #转发IP+端口 启动haproxy/usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/conf/haproxy.cfg 查看nginx是否启动：ps -ef | grep haproxy 打开防火墙 博主使用的CentOS7，开放防火墙的8989端口 firewall-cmd --zone=public --add-port=8989/tcp --permanent firewall-cmd --reload 这里只打开了haproxy的监控端口，后续代理了什么端口也要相应的打开防火墙端口。 至此haproxy已经搭建完成，去做测试吧WwW]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下nginx安装]]></title>
    <url>%2Fblogs%2F2970943405.html</url>
    <content type="text"><![CDATA[安装依赖包 nginx部署安装对环境有要求，一键安装以下依赖即可。 yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel 下载并解压安装包 先新建一个文件夹，博主喜欢在/var下面安装服务器软件 cd /var mkdir nginx cd nginx 下载tar包并解压缩 wget http://nginx.org/download/nginx-1.13.7.tar.gz &amp;&amp; tar -xvf nginx-1.13.7.tar.gz 安装nginx 进入nginx目录 cd /var/nginx 执行编译命令 ./configure &amp;&amp; make &amp;&amp; make install 配置nginx.conf 编辑配置文件 vim /usr/local/ngnix/conf/nginx.conf 先将端口改为8081，因为80端口多是apeache占用的端口，对于开发者来说apeache端口尽量不要修改，变更nginx代理端口显得更为妥当。 启动nginx/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf 查看nginx是否启动：ps -ef | grep nginx 打开防火墙 博主使用的CentOS7，开放防火墙的8081端口 firewall-cmd --zone=public --add-port=8081/tcp --permanent firewall-cmd --reload 之后访问该ip端口即可看到nginx界面 访问nginx服务 见到该页面即搭建成功WvW]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Alibaba Cloud Toolkit插件一键部署项目]]></title>
    <url>%2Fblogs%2F593089678.html</url>
    <content type="text"><![CDATA[Cloud Toolkit是一个IDE 插件，帮助开发者更高效地开发、测试、诊断并部署应用。使用本插件，开发者能够方便地将本地应用一键部署到任意机器，或 ECS、EDAS、Kubernetes；并支持高效执行终端命令和 SQL 等。 截止博主目前更新为止，版本已更新至2019.6.2，具体下载地址 下载Alibaba Cloud Toolkit插件插件博主开发使用的是idea，所以在本文中所有插件相关操作均为idea内使用，其他开发工具请自行百度。在idea的Plugins中搜索Alibaba Cloud Toolkit，下载好如下图所示： 插件配置安装好插件后进行一些简单的配置 博主这里使用的是SSH进行连接，一般公司服务器都会使用SSH，Accounts令牌配置是从阿里云上获取两个key。有自己服务器的朋友可以使用Accounts令牌进行配置。 配置之后，就可以在项目下进行使用了。 点击图上位置进入插件内 项目部署根据之前SSH的配置，会在图上出现部署的服务器地址。 Target Directory 表示项目在服务器下tomcat的webapps位置，项目的war包就是放在此路径下，这里博主贴出自己的路径/mnt2/pm-project/qhcon-netty/webapps。 Command表示war包上传至服务器之后需要执行的命令。这里博主使用的是一段组合命令，用于删除一些因为运行产生的的文件以及后续项目的启动。 mv /mnt2/pm-project/qhcon-netty/webapps/mc-0.0.1-SNAPSHOT.war ROOT.war &amp;&amp; kill -9 `cat /mnt2/pm-project/qhcon-netty/tomcat.pid` &amp;&amp; rm -rf /mnt2/pm-project/qhcon-netty/logs/* &amp;&amp; rm -rf /mnt2/pm-project/qhcon-netty/work/* &amp;&amp; sh /mnt2/pm-project/qhcon-netty/bin/startup.sh 注意：此处的kill -9命令需要单独配置 修改$TOMCAT_HOME/bin/catalina.sh文件，在PRGDIR下面一行添加CATALINAPID参数行，如下： PRGDIR=`dirname "$PRG"` CATALINA_PID=$PRGDIR/tomcat.pid 博主使用的是maven项目，所以使用maven进行项目的打包。 如果需要运行其他命令，如npm或Gradle编译，均可在此处进行额外配置。 之后点击Apply后点击RUN即可一键部署项目。 额外操作 查看日志 可以直接使用SSH控制台输入命令查看，也在插件中输入命令后直接打开控制台查看。 此插件还可以查看数据库，RDS之类的数据，有兴趣的朋友可以网上找资料查看。个人认为部署功能最为实用！ 后记后续可能会出别的教程，也可能不会，以上\~]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Alibaba Cloud Toolkit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty的WebSocket客户端通过SSL连接服务器]]></title>
    <url>%2Fblogs%2F784033432.html</url>
    <content type="text"><![CDATA[生成SSL证书 本地测试 因为是测试，直接使用jdk自带的keytool工具生成自签名证书（注：自签名证书是不被浏览器认可的，只能用于测试） 打开cmd 输入命令（复制啊）：keytool -genkey -keysize 2048 -validity 365 -keyalg RSA -keypass netty123 -storepass netty123 -keystore wss.jks 阿里云测试 通过域名可取得免费证书(百度) 在ChannelPipeline添加SslHandler首先写个工具类：SslUtil配置SSLContext/** * @author chihiro * @version V1.0 * @date 2019-06-15 09:00:00 */ public static SSLContext createSSLContext(String type ,String path ,String password) throws Exception { // 证书类型"JKS、PKCS12" KeyStore ks = KeyStore.getInstance(type); // 证书存放地址 InputStream ksInputStream = new FileInputStream(path); ks.load(ksInputStream, password.toCharArray()); //KeyManagerFactory充当基于密钥内容源的密钥管理器的工厂。 //getDefaultAlgorithm:获取默认的 KeyManagerFactory kmf = KeyManagerFactory.getInstance(KeyManagerFactory.getDefaultAlgorithm());KeyManagerFactory 算法名称。 kmf.init(ks, password.toCharArray()); //SSLContext的实例表示安全套接字协议的实现，它充当用于安全套接字工厂或 SSLEngine 的工厂。 SSLContext sslContext = SSLContext.getInstance("TLS"); sslContext.init(kmf.getKeyManagers(), null, null); return sslContext; } 在ChannelInitialize的子类里面加入SSL/** * @author chihiro * @version V1.0 * @date 2019-06-15 09:00:00 */ public class MyPipeline extends ChannelInitializer&lt;SocketChannel> { @Override public void initChannel(SocketChannel ch) throws Exception { //阿里云证书与此处配置不同，类型为PKCS12 SSLContext sslContext = SslUtil.createSSLContext("JKS","D://wss.jks","netty123"); //SSLEngine 此类允许使用ssl安全套接层协议进行安全通信 SSLEngine engine = sslContext.createSSLEngine(); engine.setUseClientMode(false); //SslHandler应当放在首位 ch.pipeline().addLast(new SslHandler(engine)); ch.pipeline().addLast(new IdleStateHandler(5, 0, 0, TimeUnit.SECONDS)); ch.pipeline().addLast("http-codec", new HttpServerCodec()); ch.pipeline().addLast("aggregator", new HttpObjectAggregator(65536)); ch.pipeline().addLast("http-chunked", new ChunkedWriteHandler()); ch.pipeline().addLast(new AcceptorIdleStateTrigger()); ch.pipeline().addLast("handler", new WebSocketHandler()); } } JS文件的URLvar url = &quot;wss://localhost:8000/ws&quot;; 注：阿里云证书不可加【www.】前缀 /ws后缀属于自己定义的，具体定义请查看自己项目中的配置类 运行 运行服务端，在浏览器地址栏输入https://localhost:8000/ 浏览器会提示这是不安全的连接（浏览器不信任自签名证书，如果有域名可以自己申请一个证书，网上有免费测试版的证书），添加例外信任，再在html页面上右键获得它的本地路径 在浏览器中运行。 连接成功。]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Netty</tag>
        <tag>SSL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[srs流媒体服务器集群搭建]]></title>
    <url>%2Fblogs%2F1651636328.html</url>
    <content type="text"><![CDATA[单台服务器做直播，总归有单点风险，利用SRS的[Forward机制][1] + [Edge Server][2]设计，可以很容易搭建一个大规模的高可用集群，示意图如下 源站服务器集群：origin server cluster，可以借助forward机制，仅用少量的服务器，专用于处理推流请求。 边缘服务器集群：edge server cluster，可以用N台机器，从源站拉流，用于较大规模的实时播放。 源站前置负载均衡（硬件或软件负载均衡都行），上图中用haproxy来实现tcp的软负载均衡。 边缘服务器前置反向代理（比如：nginx），用于提供统一的播放地址，同时解决跨域问题，给客户端拉流播放。 这样架构的好处有以下： 不管是源站集群，还是连缘服务器集群，均可水平扩展，理论上没有上限。 源站可以仅用较少的机器，比如2主2从，就能实现一个高可用且性能尚可的集群（如果业务量不大，连slave server都可以省掉） 边缘服务器集群，可以根据实际用户量随时调整规模，另外hls切片，可以放在edge server上切片，减轻源站服务器压力。 开始实战，博主2台服务器(centos 7.x)，只能在每个虚拟机上用不同的端口启动多个srs实例，模拟master/slave/edge server （注：大家根据实际情况，将下面的ip换成自己真实的ip地址） 执行此命令拉取srs源文件wget http://ossrs.net/srs.release/releases/files/SRS-CentOS6-x86_64-latest.zip &amp;&amp; unzip -q SRS-CentOS6-x86_64-latest.zip srs文件夹路径/mnt/srs/SRS-CentOS6-x86_64-2.0.263 进入SRS文件夹内执行命令sudo bash INSTALL编译源文件 srs编译后配置文件路径/usr/local/srs/conf 在conf下新建pm文件夹mkdir pm，后面所有自己的集群配置文件都会放入此文件夹 master配置配置：/usr/local/srs/conf/pm/master.conf listen 1945; max_connections 1000; pid ./objs/pids/srs.master.pid srs_log_tank file; srs_log_file ./objs/logs/master/srs.master.log; http_api { enabled on; listen 1995; } http_server { enabled on; listen 8180; dir ./objs/nginx/html; } stats { network 0; disk sda sdb xvda xvdb; } vhost __defaultVhost__ { forward 172.**.***.71:1946 172.**.***.71:1947 172.**.***.73:1946 172.**.***.73:1947; } 注：最后一段的forward，表示将视频流转发到4台slave服务器 slave配置配置：/usr/local/srs/conf/pm/slave1.conf、/usr/local/srs/conf/pm/slave2.conf slave1: listen 1946; max_connections 1000; pid ./objs/pids/srs.slave1.pid srs_log_tank file; srs_log_file ./objs/logs/slave/srs.slave1.log; http_api { enabled on; listen 1996; } http_server { enabled on; listen 8181; dir ./objs/nginx/html; } stats { network 0; disk sda sdb xvda xvdb; } vhost __defaultVhost__ { } slave2: listen 1947; max_connections 1000; pid ./objs/pids/srs.slave2.pid srs_log_tank file; srs_log_file ./objs/logs/slave/srs.slave2.log; http_api { enabled on; listen 1997; } http_server { enabled on; listen 8182; dir ./objs/nginx/html; } stats { network 0; disk sda sdb xvda xvdb; } vhost __defaultVhost__ { } edge配置配置：/usr/local/srs/conf/pm/edge1.conf、/usr/local/srs/conf/pm/edge2.conf edge1: listen 1948; max_connections 1000; pid ./objs/pids/srs.edge1.pid srs_log_tank file; srs_log_file ./objs/logs/edge/srs.edge1.log; http_api { enabled on; listen 1998; } http_server { enabled on; listen 8183; dir ./objs/nginx/html; } stats { network 0; disk sda sdb xvda xvdb; } vhost __defaultVhost__ { http_remux{ enabled on; mount [vhost]/[app]/[stream].flv; hstrs on; } hls{ enabled on; hls_path ./objs/nginx/html; hls_fragment 3; hls_window 60; } mode remote; origin 172.**.***.71:1945 172.**.***.71:1946 172.**.***.71:1947 172.**.***.73:1945 172.**.***.73:1946 172.**.***.73:1947; } edge2: listen 1949; max_connections 1000; pid ./objs/pids/srs.edge2.pid srs_log_tank file; srs_log_file ./objs/logs/edge/srs.edge2.log; http_api { enabled on; listen 1999; } http_server { enabled on; listen 8184; dir ./objs/nginx/html; } stats { network 0; disk sda sdb xvda xvdb; } vhost __defaultVhost__ { http_remux{ enabled on; mount [vhost]/[app]/[stream].flv; hstrs on; } hls{ enabled on; hls_path ./objs/nginx/html; hls_fragment 3; hls_window 60; } mode remote; origin 172.**.***.71:1945 172.**.***.71:1946 172.**.***.71:1947 172.**.***.73:1945 172.**.***.73:1946 172.**.***.73:1947; } 注：最后一段的origin 将所有master、slave均做为视频源(origin server)，如果播放时，edge发现自己机器上没有数据，会从origin配置的这些源站上去拉视频流。 每台虚拟机上，依次启动：slave1、slave2、master、edge1、edge2 cd /usr/local/srs sudo ./objs/srs -c ./conf/pm/slave1.conf sudo ./objs/srs -c ./conf/pm/slave2.conf sudo ./objs/srs -c ./conf/pm/master.conf sudo ./objs/srs -c ./conf/pm/edge1.conf sudo ./objs/srs -c ./conf/pm/edge2.conf 启动成功后，建议先验证下是否工作正常： 测试前先打开阿里云安全组上述端口，并打开防火墙端口。 阿里云开启安全组端口在此不做说明，具体方法请自行百度。 linux开启防火墙端口命令 firewall-cmd --zone=public --add-port=1945-1949/tcp --permanent firewall-cmd --zone=public --add-port=1995-1999/tcp --permanent firewall-cmd --zone=public --add-port=8180-8184/tcp --permanent firewall-cmd --reload 可以用obs向每个master或slave推流试试，比如 rtmp://47.**.***.38:1945/live/test 或 rtmp://101. **.***.215:1945/live/test，如果推流不报错，说明master/slave工作正常 注意：此处使用的是外网ip，而配置中使用的是内网ip通信，务必区分！ 然后用vlc播放器，验证从slave/edge这些服务器上拉流(比如 rtmp://47.**.***.38:1945/live/test 或 rtmp://101.**.***.215:1945/live/test，是否播放正常。 srs日志切割 这里说一下日志切割：在/etc/logrotate.d/目录下新建如下5个文件： srs_edge1: /usr/local/srs/objs/logs/edge/srs.edge1.log{ copytruncate daily rotate 7 missingok compress size 16M } srs_edge2: /usr/local/srs/objs/logs/edge/srs.edge2.log{ copytruncate daily rotate 7 missingok compress size 16M } srs_master: /usr/local/srs/objs/logs/master/srs.master.log{ copytruncate daily rotate 7 missingok compress size 16M } srs_slave1: /usr/local/srs/objs/logs/slave/srs.slave1.log{ copytruncate daily rotate 7 missingok compress size 16M } srs_slave2: /usr/local/srs/objs/logs/slave/srs.slave2.log{ copytruncate daily rotate 7 missingok compress size 16M } 之后重启日志切割脚本：/usr/sbin/logrotate /etc/logrotate.conf haproxy配置启动如果上述2个步骤均验证ok，接下来就是如何配置haproxy haproxy可做高性能负载均衡服务器，在其中一台机器上安装haproxy，这里我们使用47.**.***.38： yum install haproxy (非常简单) vim /etc/haproxy/haproxy.cfg (修改配置文件) #--------------------------------------------------------------------- # Example configuration for a possible web application. See the # full configuration options online. # # http://haproxy.1wt.eu/download/1.4/doc/configuration.txt # #--------------------------------------------------------------------- #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/stats defaults mode tcp log global option tcplog option dontlognull option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 listen srs-cluster bind *:1935 mode tcp balance roundrobin server master1 172.**.***.71:1945 server master2 172.**.***.73:1945 注：关键是最后一段，把本机1935端口，转发到后端2台master服务器的1945端口。 sudo systemctl restart haproxy (重启haproxy) 重启haproxy成功后，可以用obs推流到 rtmp://haproxy_server_ip:1935/live/test 试下推流是否正常，如果ok，可以尝试把其中一台master停掉，看看是否有影响。 nginx配置启动最后是nginx出场了，ngnix的安装类似haproxy，yum install nginx 即可，关键是配置： 新建配置文件nginx_srs.conf #user nobody; worker_processes 1; #error_log logs/error.log; #error_log logs/error.log notice; #error\_log logs/error.log info; #pid logs/nginx.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; upstream srs { ip_hash; server 172.**.***.71:8183; server 172.**.***.71:8184; server 172.**.***.73:8183; server 172.**.***.73:8184; } server { listen 80; server_name localhost; location ~ /* { proxy_pass http://srs; add_header Cache-Control no-cache; add_header Access-Control-Allow-Origin *; } location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } include servers /*; } nginx启动：/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx_srs.conf nginx重启：/usr/local/nginx/sbin/nginx -s reload 注：新增一个upstream用于指定要转发的edge服务器节点，然后在location ~ /* 这里proxy_pass 指定upstream的名字即可（location ~ /* 切记要写在 location / 前面）。这样配置后，访问 http://nginx\_server\_ip/live/test.m3u8 理论上就能转到后端的edge服务器。 后记发现一个比较严重的bug，nginx无法转发master与slave的流到edge，导致hls的切片无法获取。后续再排查，单独每个edge服务器可以正常工作。 nginx无法分发流的问题可以通过在haproxy配置分发解决，在实际测试中可以流可以得到分发并切片。 博客参考：[开源流媒体服务器SRS学习笔记(4) - Cluster集群方案][3]]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>srs</tag>
        <tag>流媒体服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FastDFS的Java客户端]]></title>
    <url>%2Fblogs%2F504695146.html</url>
    <content type="text"><![CDATA[前言 前段时间搭建了一个FastDFS文件服务器想作为博客的图床，感觉服务器有点抗不太住，所以弃用了。但是既然搭都搭完了，不把个Java客户端弄出来总觉得自己的努力有点白费了。话不多说，上代码！ 新建项目新建SpringBoot工程，这里命名为：JavaFastDFSClient 编辑pom文件在pom文件中引入如下jar包： &lt;dependency> &lt;groupId>org.springframework.boot&lt;/groupId> &lt;artifactId>spring-boot-starter-test&lt;/artifactId> &lt;scope>test&lt;/scope> &lt;/dependency> &lt;!--引入FastDFS工具类--> &lt;dependency> &lt;groupId>cn.bestwu&lt;/groupId> &lt;artifactId>fastdfs-client-java&lt;/artifactId> &lt;version>1.27&lt;/version> &lt;/dependency> &lt;!--引入IO工具类库--> &lt;dependency> &lt;groupId>commons-io&lt;/groupId> &lt;artifactId>commons-io&lt;/artifactId> &lt;version>2.6&lt;/version> &lt;/dependency> 编辑配置文件在resources目录下新建一个名为fdfs_client.conf的文件 connect_timeout = 60 network_timeout = 60 charset = UTF-8 # Tracker配置文件中配置的http端口 http.tracker_http_port = 9989 http.anti_steal_token = no http.secret_key = FastDFS1234567890 # Tracker服务器地址 tracker_server = 你自己的IP:22122 如果按照博主之前的文章搭建的文件服务器，那么http.tracker_http_port的值应为9989，Tracker服务器地址的地址配置为自己的服务器IP端口，http.secret_key博主没有做配置，这里使用默认的就好。 FastDFS工具类其中Slf4j可以去掉，博主为了方便直接进行了引入。 import lombok.extern.slf4j.Slf4j; import org.csource.common.NameValuePair; import org.csource.fastdfs.*; import org.springframework.core.io.ClassPathResource; import java.io.ByteArrayInputStream; import java.io.IOException; import java.io.InputStream; /** * @author chihiro * @date 2019/04/08 */ @Slf4j public class FastDFSClient { static { try { String filePath = new ClassPathResource("fdfs_client.conf").getFile().getAbsolutePath(); ClientGlobal.init(filePath); } catch (Exception e) { log.error("FastDFS Client Init Fail!", e); } } /** * 文件上传 * * @param file * @return 返回String[] [0]=groupName [1]=remoteFileName */ public static String[] upload(FastDFSFile file) { log.info("File Name: " + file.getName() + "File Length:" + file.getContent().length); NameValuePair[] meta_list = new NameValuePair[1]; meta_list[0] = new NameValuePair("author", file.getAuthor()); long startTime = System.currentTimeMillis(); String[] uploadResults = null; StorageClient storageClient = null; String path = null; try { storageClient = getTrackerClient(); uploadResults = storageClient.upload_file(file.getContent(), file.getExt(), meta_list); log.info("upload_file time used:" + (System.currentTimeMillis() - startTime) + " ms"); if (uploadResults == null &amp;&amp; storageClient != null) { log.error("upload file fail, error code:" + storageClient.getErrorCode()); } String groupName = uploadResults[0]; String remoteFileName = uploadResults[1]; log.info("upload file successfully!!!" + "group_name:" + groupName + ", remoteFileName:" + " " + remoteFileName); return uploadResults; } catch (IOException e) { log.error("IO Exception when uploadind the file:" + file.getName(), e); } catch (Exception e) { log.error("Non IO Exception when uploadind the file:" + file.getName(), e); } return null; } public static FileInfo getFile(String groupName, String remoteFileName) { try { StorageClient storageClient = getTrackerClient(); return storageClient.get_file_info(groupName, remoteFileName); } catch (IOException e) { log.error("IO Exception: Get File from Fast DFS failed", e); } catch (Exception e) { log.error("Non IO Exception: Get File from Fast DFS failed", e); } return null; } /** * 文件下载 * * @param groupName * @param remoteFileName * @return */ public static InputStream downFile(String groupName, String remoteFileName) { try { StorageClient storageClient = getTrackerClient(); byte[] fileByte = storageClient.download_file(groupName, remoteFileName); InputStream ins = new ByteArrayInputStream(fileByte); return ins; } catch (IOException e) { log.error("IO Exception: Get File from Fast DFS failed", e); } catch (Exception e) { log.error("Non IO Exception: Get File from Fast DFS failed", e); } return null; } /** * 删除文件 * * @param groupName * @param remoteFileName * @return */ public static void deleteFile(String groupName, String remoteFileName) throws Exception { StorageClient storageClient = getTrackerClient(); int i = storageClient.delete_file(groupName, remoteFileName); log.info("delete file successfully!!!"); } public static StorageServer[] getStoreStorages(String groupName) throws IOException { TrackerClient trackerClient = new TrackerClient(); TrackerServer trackerServer = trackerClient.getConnection(); return trackerClient.getStoreStorages(trackerServer, groupName); } public static ServerInfo[] getFetchStorages(String groupName, String remoteFileName) throws IOException { TrackerClient trackerClient = new TrackerClient(); TrackerServer trackerServer = trackerClient.getConnection(); return trackerClient.getFetchStorages(trackerServer, groupName, remoteFileName); } public static String getTrackerUrl() throws IOException { return "http://" + getTrackerServer().getInetSocketAddress().getHostString() + ":" + ClientGlobal.getG_tracker_http_port() + "/"; } private static StorageClient getTrackerClient() throws IOException { TrackerServer trackerServer = getTrackerServer(); StorageClient storageClient = new StorageClient(trackerServer, null); return storageClient; } private static TrackerServer getTrackerServer() throws IOException { TrackerClient trackerClient = new TrackerClient(); TrackerServer trackerServer = trackerClient.getConnection(); return trackerServer; } } 测试类下面几个测试类实现了最基本的上传、下载以及删除功能。 import cn.hutool.core.io.FileUtil; import cn.hutool.core.util.ArrayUtil; import com.alibaba.fastjson.JSON; import lombok.extern.slf4j.Slf4j; import org.csource.fastdfs.FileInfo; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import java.io.File; import java.io.IOException; import java.io.InputStream; @RunWith(SpringRunner.class) @SpringBootTest @Slf4j public class FastDfsApplicationTests { @Test public void upload() throws IOException { File file = FileUtil.file("E:\\mnt\\file\\cms\\2019\\02\\22\\10.jpg"); String fileName = FileUtil.getName(file); String extName = FileUtil.extName(fileName); System.out.println(fileName + extName); byte[] bytes = FileUtil.readBytes(file); FastDFSFile fastDFSFile = new FastDFSFile(); fastDFSFile.setName(fileName); fastDFSFile.setExt(extName); fastDFSFile.setContent(bytes); fastDFSFile.setAuthor("333"); String[] fileAbsolutePath = FastDFSClient.upload(fastDFSFile); if (!ArrayUtil.isNotEmpty(fileAbsolutePath)) { // 上传失败逻辑 System.out.println("上传失败"); } else { //TODO 正式环境切换 String path = FastDFSClient.getTrackerUrl() + fileAbsolutePath[0] + "/" + fileAbsolutePath[1]; log.info(path); log.info(JSON.toJSONString(fileAbsolutePath)); } } @Test public void del() throws Exception { FastDFSClient.deleteFile("group1","M00/00/00/rBEcC1ykgdiALaceAACZsuwCbKE956.jpg"); } @Test public void download() throws Exception { InputStream inputStream = FastDFSClient.downFile("group1", "M00/00/00/rBEcC1ykgdiALaceAACZsuwCbKE956.jpg"); FileUtil.writeFromStream(inputStream,"E:\\mnt\\file\\6666.jpg"); } @Test public void getFile() throws Exception { FileInfo fileInfo = FastDFSClient.getFile("group1", "M00/00/00/rBEcC1ykgdiALaceAACZsuwCbKE956.jpg"); log.info(JSON.toJSONString(fileInfo)); } } 后记 这套代码博主自己测试可以使用，但未经深度测试，只能算作一个参考demo。 若遇到其他Bug，请联系博主。]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>FastDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FastDFS-Nginx分布式文件系统搭建]]></title>
    <url>%2Fblogs%2F4286120219.html</url>
    <content type="text"><![CDATA[因为不想把博客的图片放在别人的图床上，所以自己研究了个图片服务器。本人搭建的为单机方案，当然此服务器自带集群方案，只是博主没有配置。有需要集群配置方案的也很简单，改几个配置就可以了。具体集群步骤可以问问度娘。首先感谢牧佑大佬的试错总结，没有他的总结，我也写不出来这篇博客，当然我也出现了不少未知错误。话不多说，直接开始！ 首先声明：本文不介绍Nginx和FastDfs的来源及应用场景，文中出现的120.\*\*.\*\*\*.165地址为博主服务器ip地址，实际搭建时请更改为自己的ip！fastdfs 5.11 版本对照：Version 5.11对应的fastdfs-nginx-module的Version 1.20fastdfs 5.10 版本对照：Version 5.10对应的fastdfs-nginx-module的Version 1.19** 如果版本不对应，后期安装会报错！！！*\* 安装FastDfs作者的GitHub地址：https://github.com/happyfish100（本次所需的工具大部分都可以找到）首先搭建需要用到的所有工具截图 在此直接公布下载地址，毕竟时间宝贵！ fastdfs 5.11 点击如下图即可，完成下载。https://github.com/happyfish100/fastdfs/releases fastdfs-client-java-master 点击如下图即可，完成下载。https://github.com/happyfish100/fastdfs-client-java fastdfs-nginx-module-master 点击如下图即可，完成下载。https://github.com/happyfish100/fastdfs-nginx-module libfastcommon-master 点击如下图即可，完成下载。https://github.com/happyfish100/libfastcommon nginx-1.12.0.tar 点击如下图即可，完成下载。http://nginx.org/download/ 到此，所需要的工具已经下载完毕。下面开始搭建，博主使用的是阿里云轻量级服务器下的linux系统，下面的工具运行命令可看情况安装，但实际安装后已存在的工具不会重复安装，所以完全可以直接复制过去执行一遍，以防万一。首先下载 所需全部工具运行命令 yum -y install zlib zlib-devel pcre pcre-devel gcc gcc-c++ openssl openssl-devel libevent libevent-devel perl unzip net-tools wget 等待下载完成 然后安装rz 命令 yum install lrzsz -y 通过rz命令 或者sftp上传到/home目录下自己新建一个目录（根据个人习惯）cd /var 进入var目录mkdir fdfs 创建fdfs文件夹cd fdfs 进入fdfs文件夹rz(或直接将文件拖拽进shell窗口) 将下载好的文件传输至服务器ls 如下图所示5个压缩文件 安装libfastcommon解压刚才上传的文件，然后进入解压完成的文件目录unzip libfastcommon-master.zip 解压libfastcommon-mastercd libfastcommon-master 进入libfastcommon-masterll我们会看到开始安装 执行 ./make.sh ./make.sh install 看看有没有报错，如果没有错误就可以执行软链接了。 ln -s /usr/lib64/libfastcommon.so /usr/local/lib/libfastcommon.so ln -s /usr/lib64/libfastcommon.so /usr/lib/libfastcommon.so ln -s /usr/lib64/libfdfsclient.so /usr/local/lib/libfdfsclient.so ln -s /usr/lib64/libfdfsclient.so /usr/lib/libfdfsclient.so 安装FastDfs然后回到/var/fdfs(或者你创建的文件下)解压fastdfsunzip fastdfs-5.11.zip解压完成进入fastdfs5.11 cd fastdfs-5.11 ./make.sh ./make.sh install 如果没有报错那么，万里长征第一步已经成功，如果报错，请根据报错提示重装。成功之后查看目录 [root@izwz9hx50rbasf6sqasl7vz fdfs]# cd /etc/fdfs/ [root@izwz9hx50rbasf6sqasl7vz fdfs]# ll -rw-r--r-- 1 root root 1461 Jun 8 21:56 client.conf.sample -rw-r--r-- 1 root root 7927 Jun 8 21:56 storage.conf.sample -rw-r--r-- 1 root root 7389 Jun 8 21:56 tracker.conf.sample 我们需要把这三个实例文件服务一份，去掉sample cp client.conf.sample client.conf cp storage.conf.sample storage.conf cp tracker.conf.sample tracker.conf 到此~FastDFS安装结束。 安装tracker创建tarcker工作目录这个目录可以自定义，用来保存tracker的data和log根据个人习惯创建下面的目录： [root@izwz9hx50rbasf6sqasl7vz ~]# cd /var/ [root@izwz9hx50rbasf6sqasl7vz var]# mkdir fastdfs [root@izwz9hx50rbasf6sqasl7vz var]# cd fastdfs/ [root@izwz9hx50rbasf6sqasl7vz fastdfs]# mkdir fastdfs_tracker [root@izwz9hx50rbasf6sqasl7vz fastdfs]# cd fastdfs_tracker/ [root@izwz9hx50rbasf6sqasl7vz fastdfs_tracker]# pwd /var/fastdfs/fastdfs_tracker #这个是我最终创建的目录 [root@izwz9hx50rbasf6sqasl7vz fastdfs_tracker]# 配置tracker cd /etc/fdfs vim tracker.conf 打开后找到下面4处然后修改即可（点点111） 1. disabled=false #默认开启 2. port=22122 #默认端口号 3. base_path=/var/fastdfs/fastdfs_tracker #刚刚创建的目录 4. http.server_port=6666 #默认端口是8080 保存修改文件启动 tracker 命令如下。 service fdfs_trackerd start 如果不能成功启动，可以通systemctl命令 systemctl start fdfs_trackerd 成功之后可以看见 [root@izwz9hx50rbasf6sqasl7vz fdfs]# service fdfs_trackerd start Starting fdfs_trackerd (via systemctl): [ OK ] 进入 （点点111） 创建的tracker目录。发现目录多了data和log两个目录 [root@izwz9hx50rbasf6sqasl7vz fdfs]# cd /var/fastdfs/fastdfs_tracker/ [root@izwz9hx50rbasf6sqasl7vz fastdfs_tracker]# ll total 0 drwxr-xr-x 2 root root 178 Jun 16 21:19 data drwxr-xr-x 2 root root 26 Jun 13 22:01 logs 然后 我们不能每次都这么启动tracker，我们需要给tracker加入开机启动首先需要给执行权限， chmod +x /etc/rc.d/rc.local 然后开始修改rc.local vim /etc/rc.d/rc.local 在配置文件最后加下最后一句话即可 #!/bin/bash # THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES # # It is highly advisable to create own systemd services or udev rules # to run scripts during boot instead of using this file. # # In contrast to previous versions due to parallel execution during boot # this script will NOT be run after all other services. # # Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure # that this script will be executed during boot. touch /var/lock/subsys/local service fdfs_trackerd start 保存，然后 查看tracker端口监听情况 [root@izwz9hx50rbasf6sqasl7vz fastdfs_tracker]# netstat -unltp|grep fdfs tcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 2233/fdfs_trackerd 到此22122端口监听成功。 安装storage为storage配置工作目录，由于storage还需要一个目录用来存储数据，所以我另外多建了一个fastdfs_storage_data [root@izwz9hx50rbasf6sqasl7vz fastdfs]# ls fastdfs_storage fastdfs_storage_data fastdfs_tracker 修改storage配置文件修改storage.conf vim /etc/fdfs/storage.conf 找到如下几处地方修改即可 1. disabled=false 2. group_name=group1 #组名，根据实际情况修改 3. port=23000 #设置storage的端口号，默认是23000，同一个组的storage端口号必须一致 4. base_path=/var/fastdfs/fastdfs_storage #设置storage数据文件和日志目录 5. store_path_count=1 #存储路径个数，需要和store_path个数匹配 6. store_path0=/var/fastdfs/fastdfs_storage_data #实际文件存储路径 7. tracker_server=120.**.***.165:22122 #我CentOS7的ip地址 8. http.server_port=8888 #设置 http 端口号 保存之后 创建软引用 ln -s /usr/bin/fdfs_storaged /usr/local/bin 启动storage service fdfs_storaged start 同理 如果不能启动可以用下述命令 systemctl start fdfs_storaged 成功应该是如下 [root@izwz9hx50rbasf6sqasl7vz fdfs]# service fdfs_stroaged start Starting fdfs_storaged (via systemctl): [ OK ] 同样设置开机启动修改rc.local vim /etc/rc.d/rc.local #!/bin/bash # THIS FILE IS ADDED FOR COMPATIBILITY PURPOSES # # It is highly advisable to create own systemd services or udev rules # to run scripts during boot instead of using this file. # # In contrast to previous versions due to parallel execution during boot # this script will NOT be run after all other services. # # Please note that you must run 'chmod +x /etc/rc.d/rc.local' to ensure # that this script will be executed during boot. touch /var/lock/subsys/local service fdfs_trackerd start service fdfs_storaged start 同样查看服务是否启动 [root@izwz9hx50rbasf6sqasl7vz fastdfs]# netstat -unltp | grep fdfs tcp 0 0 0.0.0.0:22122 0.0.0.0:* LISTEN 2233/fdfs_trackerd tcp 0 0 0.0.0.0:23000 0.0.0.0:* LISTEN 2323/fdfs_storaged 服务启动，到此fastdfs已经配置完成了。最后我们再确认一下，storage是否注册到了tracker中去。 /usr/bin/fdfs_monitor /etc/fdfs/storage.conf 成功后可以看到： ip_addr = 120.**.***.165 (localhost.localdomain) ACTIVE 的字样 ok，修改客户端配置文件 vim /etc/fdfs/client.conf base_path=/var/fastdfs/fastdfs_tracker #tracker服务器文件路径 tracker_server=120.**.***.165:22122 #tracker服务器IP地址和端口号 http.tracker_server_port=6666 # tracker 服务器的 http端口号，必须和tracker的设置对应起来 接下来上传图片到centos7为测试rz 命令选择一张照片 上传到随便一个目录但是 一定要复制出来接下来 /usr/bin/fdfs_upload_file /etc/fdfs/client.conf /root/测试.jpg #你上传的图片路径（linux上的） 成功之后会返回图片的路径 group1/M00/00/00/rBEcC1ykgdiALaceAACZsuwCbKE956.jpg 我们去刚才上传的路径查看是否上传成功 cd /var/fastdfs/fastdfs_storage_data/data ls 0 0D 1A 27 34 41 4E 5B 68 75 82 8F 9C A9 B6 C3 D0 DD EA F7 01 0E 1B 28 35 42 4F 5C 69 76 83 90 9D AA B7 C4 D1 DE EB F8 02 0F 1C 29 36 43 50 5D 6A 77 84 91 9E AB B8 C5 D2 DF EC F9 03 10 1D 2A 37 44 51 5E 6B 78 85 92 9F AC B9 C6 D3 E0 ED FA 04 11 1E 2B 38 45 52 5F 6C 79 86 93 A0 AD BA C7 D4 E1 EE FB 05 12 1F 2C 39 46 53 60 6D 7A 87 94 A1 AE BB C8 D5 E2 EF FC 06 13 20 2D 3A 47 54 61 6E 7B 88 95 A2 AF BC C9 D6 E3 F0 FD 07 14 21 2E 3B 48 55 62 6F 7C 89 96 A3 B0 BD CA D7 E4 F1 FE 08 15 22 2F 3C 49 56 63 70 7D 8A 97 A4 B1 BE CB D8 E5 F2 FF 09 16 23 30 3D 4A 57 64 71 7E 8B 98 A5 B2 BF CC D9 E6 F3 M00 0A 17 24 31 3E 4B 58 65 72 7F 8C 99 A6 B3 C0 CD DA E7 F4 0B 18 25 32 3F 4C 59 66 73 80 8D 9A A7 B4 C1 CE DB E8 F5 0C 19 26 33 40 4D 5A 67 74 81 8E 9B A8 B5 C2 CF DC E9 F6 [root@izwz9hx50rbasf6sqasl7vz data]# cd 00 [root@izwz9hx50rbasf6sqasl7vz 00]# ls 00 0D 1A 27 34 41 4E 5B 68 75 82 8F 9C A9 B6 C3 D0 DD EA F7 01 0E 1B 28 35 42 4F 5C 69 76 83 90 9D AA B7 C4 D1 DE EB F8 02 0F 1C 29 36 43 50 5D 6A 77 84 91 9E AB B8 C5 D2 DF EC F9 03 10 1D 2A 37 44 51 5E 6B 78 85 92 9F AC B9 C6 D3 E0 ED FA 04 11 1E 2B 38 45 52 5F 6C 79 86 93 A0 AD BA C7 D4 E1 EE FB 05 12 1F 2C 39 46 53 60 6D 7A 87 94 A1 AE BB C8 D5 E2 EF FC 06 13 20 2D 3A 47 54 61 6E 7B 88 95 A2 AF BC C9 D6 E3 F0 FD 07 14 21 2E 3B 48 55 62 6F 7C 89 96 A3 B0 BD CA D7 E4 F1 FE 08 15 22 2F 3C 49 56 63 70 7D 8A 97 A4 B1 BE CB D8 E5 F2 FF 09 16 23 30 3D 4A 57 64 71 7E 8B 98 A5 B2 BF CC D9 E6 F3 0A 17 24 31 3E 4B 58 65 72 7F 8C 99 A6 B3 C0 CD DA E7 F4 0B 18 25 32 3F 4C 59 66 73 80 8D 9A A7 B4 C1 CE DB E8 F5 0C 19 26 33 40 4D 5A 67 74 81 8E 9B A8 B5 C2 CF DC E9 F6 [root@localhost 00]# cd 00 [root@localhost 00]# ls rBEcC1ykgdiALaceAACZsuwCbKE956.jpg 果然我们找到了图片了。data下有256个1级目录，每级目录下又有256个2级子目录，总共65536个文件，新写的文件会以hash的方式被路由到其中某个子目录下，然后将文件数据直接作为一个本地文件存储到该目录中。然后我们HTTP访问文件http://120.**.**.165:9999/group1/M00/00/00/rBEcC1ykgdiALaceAACZsuwCbKE956.jpg我们发现，http不能直接访问到图片。这是为什么呢。原来早在4.05的时候，就remove embed HTTP support Version 4.05 2012-12-30 * client/fdfs_upload_file.c can specify storage ip port and store path index * add connection pool * client load storage ids config * common/ini_file_reader.c does NOT call chdir * keep the mtime of file same * use g_current_time instead of call time function * remove embed HTTP support HTTP请求不能访问文件的原因 我们在使用FastDFS部署一个分布式文件系统的时候，通过FastDFS的客户端API来进行文件的上传、下载、删除等操作。同时通过FastDFS的HTTP服务器来提供HTTP服务。但是FastDFS的HTTP服务较为简单，无法提供负载均衡等高性能的服务，所以FastDFS的开发者——淘宝的架构师余庆同学，为我们提供了Nginx上使用的FastDFS模块（也可以叫FastDFS的Nginx模块）。FastDFS通过Tracker服务器,将文件放在Storage服务器存储,但是同组之间的服务器需要复制文件,有延迟的问题.假设Tracker服务器将文件上传到了120...165,文件ID已经返回客户端,这时,后台会将这个文件复制到120...1651,如果复制没有完成,客户端就用这个ID在120...165取文件,肯定会出现错误。这个fastdfs-nginx-module可以重定向连接到源服务器取文件,避免客户端由于复制延迟的问题,出现错误。正是这样，FastDFS需要结合nginx，所以取消原来对HTTP的直接支持。 FastDFS的nginx模块安装配置storage nginx准备nginx安装 cd /var/fdfs 在安装nginx之前要安装nginx所需的依赖lib: yum -y install pcre pcre-devel yum -y install zlib zlib-devel yum -y install openssl openssl-devel 安装nginx并添加fastdfs-nginx-module解压nginx,和fastdfs-nginx-module: tar -zxvf nginx-1.12.0.tar.gz unzip fastdfs-nginx-module-master.zip 然后进入nginx安装目录，添加fastdfs-nginx-module： ./configure --prefix=/usr/local/nginx \ --add-module=/var/fdfs/fastdfs-nginx-module-master/src 注意，这里有个坑！一开始对nginx的插件安装并不了解，使用的是yum下载的nginx，这样下载后的nginx好像是自带了某些插件，不需要配置SSL(因为博主的博客使用nginx做的静态代理，并且使用了SSL加密)。然而！从官网下载的nginx并不带有这个插件，所有导致博主在编译的时候一直报错。因为nginx的插件是批量添加的，所以，如果配置了HTTPS代理，那么就需要按如下方式配置两个插件！ ./configure --prefix=/usr/local/nginx \ --with-http_ssl_module \ --add-module=/var/fdfs/fastdfs-nginx-module-master/src 如果没有错误信息，开始安装 make make install 这里还有个坑！make编译的时候可能会报这个错/usr/include/fastdfs/fdfs_define.h:15:27: fatal error: common_define.h: No such file or directory。下面给出解决方案：修改fastdfs-nginx-module-1.20/src/config文件，并且重新配置一次./configurengx_module_incs=&quot;/usr/include/fastdfs /usr/include/fastcommon/&quot;CORE_INCS=&quot;$CORE_INCS /usr/include/fastdfs /usr/include/fastcommon/&quot;配置完毕后再次./configure后进行make。nginx的默认目录是/usr/local/nginx 开始 配置storage nginx root@izwz9hx50rbasf6sqasl7vz nginx-1.12.0]# cd /usr/local/nginx [root@izwz9hx50rbasf6sqasl7vz nginx]# ll 修改nginx.conf: [root@izwz9hx50rbasf6sqasl7vz nginx]# cd conf/ [root@izwz9hx50rbasf6sqasl7vz conf]# ls fastcgi.conf koi-win scgi_params fastcgi.conf.default mime.types scgi_params.default fastcgi_params mime.types.default uwsgi_params fastcgi_params.default nginx.conf uwsgi_params.default koi-utf nginx.conf.default win-utf [root@izwz9hx50rbasf6sqasl7vz conf]# vi nginx.conf 修改listen 9999.然后 新增本地location`bashserver { listen 9999; server_name localhost; location / { root html; index index.html index.htm; } location /group1/M00 { root /var/fastdfs/fastdfs_storage_data/data; ngx_fastdfs_module; } } 然后进入FastDFS安装时的解压过的目录 ```bash [root@izwz9hx50rbasf6sqasl7vz fastdfs-5.11]# cd /var/fdfs/fastdfs-5.11/conf [root@izwz9hx50rbasf6sqasl7vz conf]# ls anti-steal.jpg http.conf storage.conf tracker.conf client.conf mime.types storage_ids.conf 将http.conf和mime.types拷贝到/etc/fdfs目录下 cp http.conf /etc/fdfs/ cp mime.types /etc/fdfs/ 另外还需要把fastdfs-nginx-module安装目录中src目录下的mod_fastdfs.conf也拷贝到/etc/fdfs目录下： cp /var/fdfs/fastdfs-nginx-module-master/src/mod_fastdfs.conf /etc/fdfs/ 对刚刚拷贝的mod_fastdfs.conf文件进行修改： vim /etc/fdfs/mod_fastdfs.conf base_path=/var/fastdfs/fastdfs_storage #保存日志目录 tracker_server=120.**.***.165:22122 #tracker服务器的IP地址以及端口号 storage_server_port=23000 #storage服务器的端口号 url_have_group_name = true #文件 url 中是否有 group 名 store_path0=/var/fastdfs/fastdfs_storage_data #存储路径 group_count = 3 #设置组的个数，事实上这次只使用了group1 在文件的最后，设置group [group1] group_name=group1 storage_server_port=23000 store_path_count=1 store_path0=/var/fastdfs/fastdfs_storage_data store_path1=/var/fastdfs/fastdfs_storage_data # group settings for group #2 # since v1.14 # when support multi-group, uncomment following section as neccessary [group2] group_name=group2 storage_server_port=23000 store_path_count=1 store_path0=/var/fastdfs/fastdfs_storage_data [group3] group_name=group3 storage_server_port=23000 store_path_count=1 store_path0=/var/fastdfs/fastdfs_storage_dat 创建M00至storage存储目录的符号连接： ln -s /var/fastdfs/fastdfs_storage_data/data/ /var/fastdfs/fastdfs_storage_data/data/M00 启动nginx: /usr/local/nginx/sbin/nginx 成功启动： [root@localhost conf]# /usr/local/nginx/sbin/nginx ngx_http_fastdfs_set pid=1231 恭喜你，storage的nginx已配置成功。接下来，我们还要继续配置tracker的nginx。 配置tracker nginx一样的还是修改nginx.conf。需将upstream指向tracker的nginx地址。 vim /usr/local/nginx/conf/nginx.conf upstream fdfs_group1 { server 127.0.0.1:9999; } server { listen 9989; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location /group1/M00 { proxy_pass http://fdfs_group1; } } 重新加载nginx的配置文件: [root@localhost conf]# /usr/local/nginx/sbin/nginx -s reload 如果 访问不了 那就修改防火墙吧(阿里服务器上请不要随意关闭防火墙，可能是安全组没有打开！) firewall-cmd --zone=public --add-port=23000/tcp --permanent #开户端口号 或者 systemctl enable firewalld.service #开启防火墙 systemctl stop firewalld.service #关闭防火墙(开机会仍会启动) systemctl disable firewalld.service #禁用防火墙(开机后不再启动) 然后在找刚才那个路径 测试OK，到此已经结束，大功告成\~ 后记 本篇博客基于网上很多资料完成，按照流程搭建下来不会报错。但碍于linux环境的复杂多样，如果遇到未知错误，请多耐心查找原因(百度是个好东西！)。当然也可以联系博主~博主有时间会解答的噢。 FastDFS的Java客户端，点我达~]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>FastDFS</tag>
        <tag>Nginx</tag>
        <tag>分布式文件系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java面向对象设计之适配器模式]]></title>
    <url>%2Fblogs%2F157566173.html</url>
    <content type="text"><![CDATA[模式动机 在软件开发中采用类似于电源适配器的设计和编码技巧被称为适配器模式。 通常情况下，客户端可以通过目标类的接口访问它所提供的服务。有时，现有的类可以满足客户类的功能需要，但是它所提供的接口不一定是客户类所期望的，这可能是因为现有类中方法名与目标类中定义的方法名不一致等原因所导致的。 在这种情况下，现有的接口需要转化为客户类期望的接口，这样保证了对现有类的重用。如果不进行这样的转化，客户类就不能利用现有类所提供的功能，适配器模式可以完成这样的转化。 在适配器模式中可以定义一个包装类，包装不兼容接口的对象，这个包装类指的就是适配器(Adapter)，它所包装的对象就是适配者(Adaptee)，即被适配的类。 适配器提供客户类需要的接口，适配器的实现就是把客户类的请求转化为对适配者的相应接口的调用。也就是说：当客户类调用适配器的方法时，在适配器类的内部将调用适配者类的方法，而这个过程对客户类是透明的，客户类并不直接访问适配者类。因此，适配器可以使由于接口不兼容而不能交互的类可以一起工作。这就是适配器模式的模式动机。 模式定义 适配器模式(Adapter Pattern) ：将一个接口转换成客户希望的另一个接口，使接口不兼容的那些类可以一起工作，其别名为包装器(Wrapper)。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。适配器模式是一种结构型模式。 模式结构参与角色适配器模式包含如下角色： Target：目标抽象类 Adapter：适配器类 Adaptee：适配者类 Client：客户类 UML类图 代码示例首先，是目标角色接口和具体目标实现类： /** * Target 目标角色类. * * @author blinkfox on 2018-12-11. */ public interface Target { /** * 目标角色自己的方法. */ void request(); } /** * 具体的目标角色实现类. * * @author blinkfox on 2018-12-11. */ public class ConcreteTarget implements Target { /** * 目标角色自己的方法. */ @Override public void request() { System.out.println("hello, I'm concrete target method."); } } 其次，是适配者类： /** * 适配者类. * * @author blinkfox on 2018-12-11. */ public class Adaptee { /** * 这是原有的业务逻辑方法. */ public void doSomething() { System.out.println("Hello, I'm Adaptee method."); } } 然后，是适配器角色类： /** * 适配器类. * * @author blinkfox on 2018-12-11. */ public class Adapter extends Adaptee implements Target { /** * 适配了目标角色自己的方法. */ @Override public void request() { super.doSomething(); System.out.println("适配器适配了目标角色方法."); } } 最后，是客户端场景类： /** * 客户端场景类. * * @author blinkfox on 2018-12-11. */ public class Client { /** * main方法. * * @param args 数组参数 */ public static void main(String[] args) { // 原有业务逻辑. Target target = new ConcreteTarget(); target.request(); // 增加了适配器角色后的业务逻辑. Target adaptTarget = new Adapter(); adaptTarget.request(); } } 模式分析适用环境在以下情况下可以使用适配器模式： 系统需要使用现有的类，而这些类的接口不符合系统的需要。 想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作。 优点 将目标类和适配者类解耦，通过引入一个适配器类来重用现有的适配者类，而无须修改原有代码。 增加了类的透明性和复用性，将具体的实现封装在适配者类中，对于客户端类来说是透明的，而且提高了适配者的复用性。 灵活性和扩展性都非常好，通过使用配置文件，可以很方便地更换适配器，也可以在不修改原有代码的基础上增加新的适配器类，完全符合“开闭原则”。 缺点如果一定要置换掉适配者类的一个或多个方法，就只好先做一个适配者类的子类，将适配者类的方法置换掉，然后再把适配者类的子类当做真正的适配者进行适配，实现过程较为复杂。 模式应用Sun公司在1996年公开了Java语言的数据库连接工具JDBC，JDBC使得Java语言程序能够与数据库连接，并使用SQL语言来查询和操作数据。JDBC给出一个客户端通用的抽象接口，每一个具体数据库引擎（如SQL Server、Oracle、MySQL等）的JDBC驱动软件都是一个介于JDBC接口和数据库引擎接口之间的适配器软件。抽象的JDBC接口和各个数据库引擎API之间都需要相应的适配器软件，这就是为各个不同数据库引擎准备的驱动程序。 总结 结构型模式描述如何将类或者对象结合在一起形成更大的结构。 适配器模式用于将一个接口转换成客户希望的另一个接口，适配器模式使接口不兼容的那些类可以一起工作，其别名为包装器。适配器模式既可以作为类结构型模式，也可以作为对象结构型模式。 适配器模式包含四个角色：目标抽象类定义客户要用的特定领域的接口；适配器类可以调用另一个接口，作为一个转换器，对适配者和抽象目标类进行适配，它是适配器模式的核心；适配者类是被适配的角色，它定义了一个已经存在的接口，这个接口需要适配；在客户类中针对目标抽象类进行编程，调用在目标抽象类中定义的业务方法。 在类适配器模式中，适配器类实现了目标抽象类接口并继承了适配者类，并在目标抽象类的实现方法中调用所继承的适配者类的方法；在对象适配器模式中，适配器类继承了目标抽象类并定义了一个适配者类的对象实例，在所继承的目标抽象类方法中调用适配者类的相应业务方法。 适配器模式的主要优点是将目标类和适配者类解耦，增加了类的透明性和复用性，同时系统的灵活性和扩展性都非常好，更换适配器或者增加新的适配器都非常方便，符合“开闭原则”；类适配器模式的缺点是适配器类在很多编程语言中不能同时适配多个适配者类，对象适配器模式的缺点是很难置换适配者类的方法。 适配器模式适用情况包括：系统需要使用现有的类，而这些类的接口不符合系统的需要；想要建立一个可以重复使用的类，用于与一些彼此之间没有太大关联的一些类一起工作。 参考自：适配器模式]]></content>
      <categories>
        <category>软件编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式之建造者模式]]></title>
    <url>%2Fblogs%2F2173505135.html</url>
    <content type="text"><![CDATA[一、模式动机无论是在现实世界中还是在软件系统中，都存在一些复杂的对象，它们拥有多个组成部分，如汽车，它包括车轮、方向盘、发动机等各种部件。而对于大多数用户而言，无须知道这些部件的装配细节，也几乎不会使用单独某个部件，而是使用一辆完整的汽车，可以通过建造者模式对其进行设计与描述，建造者模式可以将部件和其组装过程分开，一步一步创建一个复杂的对象。用户只需要指定复杂对象的类型就可以得到该对象，而无须知道其内部的具体构造细节。 在软件开发中，也存在大量类似汽车一样的复杂对象，它们拥有一系列成员属性，这些成员属性中有些是引用类型的成员对象。而且在这些复杂对象中，还可能存在一些限制条件，如某些属性没有赋值则复杂对象不能作为一个完整的产品使用；有些属性的赋值必须按照某个顺序，一个属性没有赋值之前，另一个属性可能无法赋值等。 复杂对象相当于一辆有待建造的汽车，而对象的属性相当于汽车的部件，建造产品的过程就相当于组合部件的过程。由于组合部件的过程很复杂，因此，这些部件的组合过程往往被“外部化”到一个称作建造者的对象里，建造者返还给客户端的是一个已经建造完毕的完整产品对象，而用户无须关心该对象所包含的属性以及它们的组装方式，这就是建造者模式的模式动机。 二、模式定义 造者模式(Builder Pattern)：将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。建造者模式属于对象创建型模式。建造者模式又可以称为生成器模式。 建造者模式是一步一步创建一个复杂的对象，它允许用户只通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节。 三、模式结构1. 角色组成建造者模式包含如下角色： Builder：抽象建造者 ConcreteBuilder：具体建造者 Director：导演者 Product：产品角色 2. 结构图 四、示例代码首先，是产品类： /** * 产品类. * * Created by blinkfox on 2016/10/8. */ public class Product { private String part1; private String part2; /* getter 和 setter方法. */ public String getPart1() { return part1; } public void setPart1(String part1) { this.part1 = part1; } public String getPart2() { return part2; } public void setPart2(String part2) { this.part2 = part2; } } 其实，是抽象的建造者Builder接口和具体的建造者ConcreteBuilder类： /** * 抽象的建造者. * * Created by blinkfox on 2016/10/8. */ public interface Builder { /** * 产品建造部分1. */ void buildPart1(); /** * 产品建造部分2. */ void buildPart2(); /** * 得到建造的产品. * * @return 产品 */ Product getResult(); } /** * 具体的建造者实现类. * * Created by blinkfox on 2016/10/8. */ public class ConcreteBuilder implements Builder { /** 产品. */ private Product product = new Product(); /** * 产品建造部分1. */ @Override public void buildPart1() { product.setPart1("编号：95757"); } /** * 产品建造部分2. */ @Override public void buildPart2() { product.setPart2("名称：小机器人"); } /** * 得到建造的产品. * * @return 产品 */ @Override public Product getResult() { return product; } } 最后，导演者Director类： /** * 导演者类. * * Created by blinkfox on 2016/10/8. */ public class Director { /** 当前需要的建造者对象. */ private Builder builder; /** * 构造方法. * * @param builder */ public Director(Builder builder) { this.builder = builder; } /** * 产品构造方法，负责调用各个零件建造方法. */ public void construct() { builder.buildPart1(); builder.buildPart2(); } } 以下是建造者模式的客户端场景类： /** * 建造者模式的客户端场景类. * * Created by blinkfox on 2016/10/8. */ public class BuilderClient { /** * 主入口方法. * * @param args 数组参数 */ public static void main(String[] args) { Builder builder = new ConcreteBuilder(); Director director = new Director(builder); director.construct(); Product product = builder.getResult(); System.out.println(product.getPart1()); System.out.println(product.getPart2()); } } 五、模式分析抽象建造者类中定义了产品的创建方法和返回方法; 建造者模式的结构中还引入了一个导演者类Director，该类的作用主要有两个：一方面它隔离了客户与生产过程；另一方面它负责控制产品的生成过程。导演者针对抽象建造者编程，客户端只需要知道具体建造者的类型，即可通过导演者类调用建造者的相关方法，返回一个完整的产品对象 在客户端代码中，无须关心产品对象的具体组装过程，只需确定具体建造者的类型即可，建造者模式将复杂对象的构建与对象的表现分离开来，这样使得同样的构建过程可以创建出不同的表现。 1. 优点建造者模式的优点： 在建造者模式中， 客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦，使得相同的创建过程可以创建不同的产品对象。 每一个具体建造者都相对独立，而与其他的具体建造者无关，因此可以很方便地替换具体建造者或增加新的具体建造者， 用户使用不同的具体建造者即可得到不同的产品对象 。 可以更加精细地控制产品的创建过程 。将复杂产品的创建步骤分解在不同的方法中，使得创建过程更加清晰，也更方便使用程序来控制创建过程。 增加新的具体建造者无须修改原有类库的代码，指挥者类针对抽象建造者类编程，系统扩展方便，符合“开闭原则”。 2. 缺点建造者模式的缺点： 建造者模式所创建的产品一般具有较多的共同点，其组成部分相似，如果产品之间的差异性很大，则不适合使用建造者模式，因此其使用范围受到一定的限制。 如果产品的内部变化复杂，可能会导致需要定义很多具体建造者类来实现这种变化，导致系统变得很庞大。 3. 适用环境在以下情况下可以使用建造者模式： 需要生成的产品对象有复杂的内部结构，这些产品对象通常包含多个成员属性。 需要生成的产品对象的属性相互依赖，需要指定其生成顺序。 对象的创建过程独立于创建该对象的类。在建造者模式中引入了指挥者类，将创建过程封装在指挥者类中，而不在建造者类中。 隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品。 4. 建造者模式与抽象工厂模式的比较 与抽象工厂模式相比，建造者模式返回一个组装好的完整产品，而抽象工厂模式返回一系列相关的产品，这些产品位于不同的产品等级结构，构成了一个产品族。 在抽象工厂模式中，客户端实例化工厂类，然后调用工厂方法获取所需产品对象，而在建造者模式中，客户端可以不直接调用建造者的相关方法，而是通过指挥者类来指导如何生成对象，包括对象的组装过程和建造步骤，它侧重于一步步构造一个复杂对象，返回一个完整的对象。 如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装可以返回一辆完整的汽车。 六、模式总结 建造者模式将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。建造者模式是一步一步创建一个复杂的对象，它允许用户只通过指定复杂对象的类型和内容就可以构建它们，用户不需要知道内部的具体构建细节。建造者模式属于对象创建型模式。 建造者模式包含如下四个角色：抽象建造者为创建一个产品对象的各个部件指定抽象接口；具体建造者实现了抽象建造者接口，实现各个部件的构造和装配方法，定义并明确它所创建的复杂对象，也可以提供一个方法返回创建好的复杂产品对象；产品角色是被构建的复杂对象，包含多个组成部件；指挥者负责安排复杂对象的建造次序，指挥者与抽象建造者之间存在关联关系，可以在其construct()建造方法中调用建造者对象的部件构造与装配方法，完成复杂对象的建造 在建造者模式的结构中引入了一个导演者类，该类的作用主要有两个：一方面它隔离了客户与生产过程；另一方面它负责控制产品的生成过程。指挥者针对抽象建造者编程，客户端只需要知道具体建造者的类型，即可通过指挥者类调用建造者的相关方法，返回一个完整的产品对象。 建造者模式的主要优点在于客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦，使得相同的创建过程可以创建不同的产品对象，每一个具体建造者都相对独立，而与其他的具体建造者无关，因此可以很方便地替换具体建造者或增加新的具体建造者，符合“开闭原则”，还可以更加精细地控制产品的创建过程；其主要缺点在于由于建造者模式所创建的产品一般具有较多的共同点，其组成部分相似，因此其使用范围受到一定的限制，如果产品的内部变化复杂，可能会导致需要定义很多具体建造者类来实现这种变化，导致系统变得很庞大。 建造者模式适用情况包括：需要生成的产品对象有复杂的内部结构，这些产品对象通常包含多个成员属性；需要生成的产品对象的属性相互依赖，需要指定其生成顺序；对象的创建过程独立于创建该对象的类；隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同类型的产品。]]></content>
      <categories>
        <category>软件编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式之单例模式]]></title>
    <url>%2Fblogs%2F606353581.html</url>
    <content type="text"><![CDATA[模式动机对于系统中的某些类来说，只有一个实例很重要，例如，一个系统中可以存在多个打印任务，但是只能有一个正在工作的任务；一个系统只能有一个窗口管理器或文件系统；一个系统只能有一个计时工具或ID（序号）生成器。 如何保证一个类只有一个实例并且这个实例易于被访问呢？定义一个全局变量可以确保对象随时都可以被访问，但不能防止我们实例化多个对象。 一个更好的解决办法是让类自身负责保存它的唯一实例。这个类可以保证没有其他实例被创建，并且它可以提供一个访问该实例的方法。这就是单例模式的模式动机。 模式定义 单例模式(Singleton Pattern)：单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。单例模式是一种对象创建型模式。单例模式又名单件模式或单态模式。 单例模式的要点有三个： 一是某个类只能有一个实例； 二是它必须自行创建这个实例； 三是它必须自行向整个系统提供这个实例。 模式结构参与角色 Singleton: 单例 UML类图 时序图 代码实现方式1. 饿汉式（推荐使用）/** * 饿汉式单例模式. * * @author blinkfox on 2017-10-23. */ public class Singleton { /** 全局唯一实例. */ private static final Singleton singleton = new Singleton(); private Singleton() {} public static Singleton getSingleton() { return singleton; } } 注：这种方式避免了多线程的同步问题，但不是懒加载。如果不需要懒加载的方式，推荐使用。 2. 非线程安全懒汉式（不推荐使用）/** * 非线程安全的懒汉式. * * @author blinkfox on 2017-10-23. */ public class Singleton { private static Singleton singleton; private Singleton() {} /** * 通过懒加载的方式获取实例，但是非线程安全. * @return Singleton实例 */ public static Singleton getSingleton() { if (singleton == null) { singleton = new Singleton(); } return singleton; } } 注：是懒加载的方式，但非线程安全。不推荐使用。 3. 低效的线程安全懒汉式（不推荐使用）/** * 低效的线程安全的懒汉式. * * @author blinkfox on 2017-10-23. */ public class Singleton { private static Singleton singleton; private Singleton() {} /** * 通过 synchronized 关键字来保证线程安全，也是懒加载的方式来获取实例. * @return Singleton实例 */ public static synchronized Singleton getSingleton() { if (singleton == null) { singleton = new Singleton(); } return singleton; } } 注：是懒加载的方式，也线程安全，但是效率很低。因为99%的情况下是不需要去同步的。不推荐使用。 4. 双重校验锁线程安全懒汉式（不推荐使用）/** * 双重校验锁线程安全懒汉式. * * @author blinkfox on 2017-10-23. */ public class Singleton { private static Singleton singleton; private Singleton() {} /** * 通过'双重校验锁'来更高效的保证线程安全，也是懒加载的方式来获取实例. * @return Singleton实例 */ public static Singleton getSingleton() { if (singleton == null) { synchronized (Singleton.class) { if (singleton == null) { singleton = new Singleton(); } } } return singleton; } } 注：是懒加载的方式，也线程安全，效率也不错。但受限于Jdk5以前的Java内存模型，仍然会有bug，Java5及之后才能正常达到单例效果。 5. 枚举式（强烈推荐使用）/** * 枚举方式的单例. * * @author blinkfox on 2017-10-23. */ public enum Singleton { INSTANCE; } 注：在《Effective Java》一书中强烈推荐使用枚举来实现单例模式，该方式简单可自由序列化；保证只有一个实例（即使使用反射机制也无法多次实例化一个枚举量）；线程安全。唯一的缺点是非懒加载方式。 6. 静态内部类（推荐使用）/** * 通过使用静态内部类的方式来实现懒加载且线程安全的创建单例. * * @author blinkfox on 2017-10-23. */ public class Singleton { private Singleton() {} /** * 静态内部类. */ private static final class SingletonHolder { private SingletonHolder() {} private static Singleton4 instance = new Singleton(); } /** * 通过懒加载的方式获取Singleton唯一实例的方法. * @return Singleton实例 */ public static Singleton getInstance() { return SingletonHolder.instance; } } 注：这种方式利用了ClassLoader的机制保证初始化instance时只有一个线程，其只有显示通过调用getInstance方法时，才会显示装载SingletonHolder类，从而实例化instance。 模式分析单例模式的目的是保证一个类仅有一个实例，并提供一个访问它的全局访问点。单例模式包含的角色只有一个，就是单例类——Singleton。 优点 提供了对唯一实例的受控访问。因为单例类封装了它的唯一实例，所以它可以严格控制客户怎样以及何时访问它，并为设计及开发团队提供了共享的概念。 由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象，单例模式无疑可以提高系统的性能。 允许可变数目的实例。我们可以基于单例模式进行扩展，使用与单例控制相似的方法来获得指定个数的对象实例。 缺点 由于单例模式中没有抽象层，因此单例类的扩展有很大的困难。 单例类的职责过重，在一定程度上违背了“单一职责原则”。因为单例类既充当了工厂角色，提供了工厂方法，同时又充当了产品角色，包含一些业务方法，将产品的创建和产品的本身的功能融合到一起。 滥用单例将带来一些负面问题，如为了节省资源将数据库连接池对象设计为单例类，可能会导致共享连接池对象的程序过多而出现连接池溢出；现在很多面向对象语言(如Java、C#)的运行环境都提供了自动垃圾回收的技术，因此，如果实例化的对象长时间不被利用，系统会认为它是垃圾，会自动销毁并回收资源，下次利用时又将重新实例化，这将导致对象状态的丢失。 适用环境在以下情况下可以使用单例模式： 系统只需要一个实例对象，如系统要求提供一个唯一的序列号生成器，或者需要考虑资源消耗太大而只允许创建一个对象。 客户调用类的单个实例只允许使用一个公共访问点，除了该公共访问点，不能通过其他途径访问该实例。 在一个系统中要求一个类只有一个实例时才应当使用单例模式。反过来，如果一个类可以有几个实例共存，就需要对单例模式进行改进，使之成为多例模式。 总结 单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。单例模式的要点有三个：一是某个类只能有一个实例；二是它必须自行创建这个实例；三是它必须自行向整个系统提供这个实例。单例模式是一种对象创建型模式。 单例模式只包含一个单例角色：在单例类的内部实现只生成一个实例，同时它提供一个静态的工厂方法，让客户可以使用它的唯一实例；为了防止在外部对其实例化，将其构造函数设计为私有。 实现单例模式，如果不需要懒加载的效果，则推荐使用枚举和饿汉式的方式；如果需要懒加载的效果，则推荐使用静态内部类来实现更好。 单例模式的主要优点在于提供了对唯一实例的受控访问并可以节约系统资源；其主要缺点在于因为缺少抽象层而难以扩展，且单例类职责过重。 单例模式适用情况包括：系统只需要一个实例对象；客户调用类的单个实例只允许使用一个公共访问点。]]></content>
      <categories>
        <category>软件编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式之工厂模式]]></title>
    <url>%2Fblogs%2F2168237024.html</url>
    <content type="text"><![CDATA[一、模式定义工厂方法模式(Factory Method Pattern)又称为工厂模式，也叫虚拟构造器(Virtual Constructor)模式或者多态工厂(Polymorphic Factory)模式，它属于类创建型模式。在工厂方法模式中，工厂父类负责定义创建产品对象的公共接口，而工厂子类则负责生成具体的产品对象，这样做的目的是将产品类的实例化操作延迟到工厂子类中完成，即通过工厂子类来确定究竟应该实例化哪一个具体产品类。 二、模式结构1. 角色组成工厂方法模式包含如下角色： Product：抽象产品 ConcreteProduct：具体产品 Factory：抽象工厂 ConcreteFactory：具体工厂 2. 结构图 3. 时序图 三、示例代码首先，是抽象的产品类和具体的产品类： /** * 抽象产品类 * Created by blinkfox on 16-6-29. */ public abstract class Product { /** * 产品类的公共方法 */ public void method1() { System.out.println("这是产品类的公共方法"); } /** * 抽象方法 */ public abstract void method2(); } /** * 具体产品类1 * Created by blinkfox on 16-6-29. */ public class ConcreteProduct1 extends Product { @Override public void method2() { System.out.println("ConcreteProduct1的method2方法"); } } /** * 具体产品类2 * Created by blinkfox on 16-6-29. */ public class ConcreteProduct2 extends Product { @Override public void method2() { System.out.println("ConcreteProduct2的method2方法"); } } 然后，是抽象的工厂类和具体的工厂类： /** * 抽象的工厂类 * Created by blinkfox on 16-6-29. */ public abstract class Factory { /** * 运用了Java中的泛型和反射技术,生成某种具体的产品 * 其输入类型可以自行设置 * @param c * @param &lt;T> * @return */ public abstract &lt;T extends Product> T createProduct(Class&lt;T> c); } /** * 具体生产产品的工厂类 * Created by blinkfox on 16-6-29. */ public class ConcreteFactory extends Factory { /** * 运用了Java中的泛型和反射技术,生成某种具体的产品 * 其输入类型可以自行设置 * @param c * @param &lt;T> * @return */ @Override public &lt;T extends Product> T createProduct(Class&lt;T> c) { Product product = null; try { product = (Product) Class.forName(c.getName()).newInstance(); } catch (Exception e) { System.out.println("生产产品出错"); e.printStackTrace(); } return (T) product; } } 最后，是客户端场景类： /** * 工厂方法模式客户端场景类 * Created by blinkfox on 16-6-29. */ public class Client { public static void main(String[] args) { Factory factory = new ConcreteFactory(); Product product1 = factory.createProduct(ConcreteProduct1.class); product1.method1(); product1.method2(); Product product2 = factory.createProduct(ConcreteProduct2.class); product2.method1(); product2.method2(); } } 四、模式分析在工厂方法模式中，核心的工厂类不再负责所有产品的创建，而是将具体创建工作交给子类去做。这个核心类仅仅负责给出具体工厂必须实现的接口，而不负责哪一个产品类被实例化这种细节，这使得工厂方法模式可以允许系统在不修改工厂角色的情况下引进新产品。 1. 优点工厂方法模式的优点： 在工厂方法模式中，工厂方法用来创建客户所需要的产品，同时还向客户隐藏了哪种具体产品类将被实例化这一细节，用户只需要关心所需产品对应的工厂，无须关心创建细节，甚至无须知道具体产品类的类名。 基于工厂角色和产品角色的多态性设计是工厂方法模式的关键。它能够使工厂可以自主确定创建何种产品对象，而如何创建这个对象的细节则完全封装在具体工厂内部。工厂方法模式之所以又被称为多态工厂模式，是因为所有的具体工厂类都具有同一抽象父类。 使用工厂方法模式的另一个优点是在系统中加入新产品时，无须修改抽象工厂和抽象产品提供的接口，无须修改客户端，也无须修改其他的具体工厂和具体产品，而只要添加一个具体工厂和具体产品就可以了。这样，系统的可扩展性也就变得非常好，完全符合“开闭原则”。 2. 缺点工厂方法模式的缺点： 在添加新产品时，需要编写新的具体产品类，而且还要提供与之对应的具体工厂类，系统中类的个数将成对增加，在一定程度上增加了系统的复杂度，有更多的类需要编译和运行，会给系统带来一些额外的开销。 由于考虑到系统的可扩展性，需要引入抽象层，在客户端代码中均使用抽象层进行定义，增加了系统的抽象性和理解难度，且在实现时可能需要用到DOM、反射等技术，增加了系统的实现难度。 3. 适用环境在以下情况下可以使用工厂方法模式： 一个类不知道它所需要的对象的类：在工厂方法模式中，客户端不需要知道具体产品类的类名，只需要知道所对应的工厂即可，具体的产品对象由具体工厂类创建；客户端需要知道创建具体产品的工厂类。 一个类通过其子类来指定创建哪个对象：在工厂方法模式中，对于抽象工厂类只需要提供一个创建产品的接口，而由其子类来确定具体要创建的对象，利用面向对象的多态性和里氏代换原则，在程序运行时，子类对象将覆盖父类对象，从而使得系统更容易扩展。 将创建对象的任务委托给多个工厂子类中的某一个，客户端在使用时可以无须关心是哪一个工厂子类创建产品子类，需要时再动态指定，可将具体工厂类的类名存储在配置文件或数据库中。 五、模式扩展工厂方法模式有很多扩展，而且与其他模式结合使用威力更大，下面介绍4种常用扩展。 1. 简单工厂模式我们这样考虑一个问题：一个模块仅需要一个工厂类，没有必要把它产生出来，使用静态的方法就可以了。因此去掉工厂类中继承的抽象类，把方法改成静态即可。通用代码如下： /** * 简单工厂模式中的工厂类 * Created by blinkfox on 16-6-29. */ public class SimpleFactory { /** * 运用了Java中的泛型和反射技术,生成某种具体的产品 * 其输入类型可以自行设置 * @param c * @param &lt;T> * @return */ public static &lt;T extends Product> T createProduct(Class&lt;T> c) { Product product = null; try { product = (Product) Class.forName(c.getName()).newInstance(); } catch (Exception e) { System.out.println("生产产品出错"); e.printStackTrace(); } return (T) product; } } /** * 简单工厂模式客户端场景类 * Created by blinkfox on 16-6-29. */ public class SimpleClient { public static void main(String[] args) { Product product1 = SimpleFactory.createProduct(ConcreteProduct1.class); product1.method1(); product1.method2(); Product product2 = SimpleFactory.createProduct(ConcreteProduct2.class); product2.method1(); product2.method2(); } } 运行结果没有发生变化，但是类图简单了，调用者也比较简单，简单工厂模式是工厂方法模式的弱化，也叫做静态工厂模式。其缺点是工厂类的扩展比较困难，不符合“开闭原则”，但它仍然是一个非常实用的设计模式。 2. 多工厂类工厂方法模式当我们在一个比较复杂的项目时，经常会遇到初始化一个对象很耗费精力的情况，所有的产品类都放到一个工厂方法中进行初始化会使代码结构不清晰。为了让结构清晰，我们就为每类产品定义一个创造者，然后由调用者自己去选择与哪个工厂方法关联。多工厂模式的通用代码如下： 多工厂模式的抽象工厂类： /** * 生成多个产品的抽象工厂类 * Created by blinkfox on 16-7-2. */ public abstract class MultiFactory { /** * 生成某种产品的方法 * @return */ public abstract Product createProduct(); } 第一种产品的创建工厂实现： /** * 生成产品1的具体工厂类1 * Created by blinkfox on 16-7-2. */ public class ConcreteFactory1 extends MultiFactory { /** * 生成产品1的方法 * @return */ @Override public Product createProduct() { return new ConcreteProduct1(); } } 第二种产品的创建工厂实现： /** * 生成产品2的具体工厂类2 * Created by blinkfox on 16-7-2. */ public class ConcreteFactory2 extends MultiFactory { /** * 生成产品2的方法 * @return */ @Override public Product createProduct() { return new ConcreteProduct2(); } } 多工厂模式的客户端场景类 /** * 多工厂方法模式客户端场景类 * Created by blinkfox on 16-7-2. */ public class MultiClient { public static void main(String[] args) { Product concreteProduct1 = (new ConcreteFactory1()).createProduct(); concreteProduct1.method1(); concreteProduct1.method2(); Product concreteProduct2 = (new ConcreteFactory2()).createProduct(); concreteProduct1.method1(); concreteProduct1.method2(); } } 3. 工厂方法的单例模式单例模式的核心要求就是在内存中只有一个对象，通过工厂方法模式也可以只在内存中生成一个对象，从而实现单例的功能。 下面是单例类，其中定义了一个private的无参构造函数，目的是不允许通过new的方式创建对象，代码如下： /** * 工厂方法模式中的单例类 * Created by blinkfox on 16-7-4. */ public class Singleton { /** * 私有化构造方法，不允许new产生一个对象 */ private Singleton() {} /** * 工厂方法模式中的单例模式业务方法 */ public void doSomething() { System.out.println("工厂方法模式中的单例模式方法。。。"); } } 以上单例类中不能通过正常的渠道建立一个对象，那单例的工厂类中如何建立一个单例对象呢？答案是通过反射方式创建，单例工厂类的代码如下： /** * 生成单例的工厂类 * Created by blinkfox on 16-7-4. */ public class SingletonFactory { private static Singleton singleton; static { try { Class c = Class.forName(Singleton.class.getName()); // 获得无参构造 Constructor constructor = c.getDeclaredConstructor(); // 设置无参构造是可访问的 constructor.setAccessible(true); // 产生一个实例对象 singleton = (Singleton) constructor.newInstance(); } catch (Exception e) { e.printStackTrace(); System.out.println("生成单例的工厂类方法中生成单例出错");zuihou } } public static Singleton getSingleton() { return singleton; } } 最后是工厂方法单例模式的客户端场景类： /** * 工厂方法单例模式客户端场景类 * Created by blinkfox on 16-7-4. */ public class SingleClient { public static void main(String[] args) { Singleton singleton = SingletonFactory.getSingleton(); singleton.doSomething(); } } 4. 工厂方法的延迟初始化何为延迟初始化？一个对象被消费完毕后，并不立即释放，工厂类保持其初始状态，等待再次使用。延迟初始化是工厂模式的一个扩展应用，其通用代码如下： /** * 延迟加载的工厂类 * Created by blinkfox on 16-7-4. */ public class LazyFactory { private static final Map&lt;String, Product> lazyMap = new HashMap&lt;String, Product>(); public static synchronized Product createProduct(String type) { Product product = null; // 如果map中已经有这个对象，则直接取出该对象即可，否则创建并放在缓存容器中 if (lazyMap.containsKey(type)) { return lazyMap.get(type); } // 根据类型创建具体的产品对象 if ("product1".equals(type)) { product = new ConcreteProduct1(); } else { product = new ConcreteProduct2(); } // 同时把对象放到缓存容器中 lazyMap.put("type", product); return product; } } 上面即为延迟加载的工厂类。代码比较简单，通过定义一个map容器来容纳所有产生的对象，如果在map容器中已经有的对象，则直接取出返回；如果没有，则根据需要的类型产生一个对象并放入到map容器中，以便下次调用。 延迟加载的工厂模式客户端场景类代码如下： /** * 延迟加载的工厂模式客户端场景类 * Created by blinkfox on 16-7-4. */ public class LazyClient { public static void main(String[] args) { Product product1 = LazyFactory.createProduct("product1"); Product product11 = LazyFactory.createProduct("product1"); } } 六、总结 工厂方法模式又称为工厂模式，它属于类创建型模式。在工厂方法模式中，工厂父类负责定义创建产品对象的公共接口，而工厂子类则负责生成具体的产品对象，这样做的目的是将产品类的实例化操作延迟到工厂子类中完成，即通过工厂子类来确定究竟应该实例化哪一个具体产品类。 工厂方法模式包含四个角色：抽象产品是定义产品的接口，是工厂方法模式所创建对象的超类型，即产品对象的共同父类或接口；具体产品实现了抽象产品接口，某种类型的具体产品由专门的具体工厂创建，它们之间往往一一对应；抽象工厂中声明了工厂方法，用于返回一个产品，它是工厂方法模式的核心，任何在模式中创建对象的工厂类都必须实现该接口；具体工厂是抽象工厂类的子类，实现了抽象工厂中定义的工厂方法，并可由客户调用，返回一个具体产品类的实例。 工厂方法模式是简单工厂模式的进一步抽象和推广。由于使用了面向对象的多态性，工厂方法模式保持了简单工厂模式的优点，而且克服了它的缺点。在工厂方法模式中，核心的工厂类不再负责所有产品的创建，而是将具体创建工作交给子类去做。这个核心类仅仅负责给出具体工厂必须实现的接口，而不负责产品类被实例化这种细节，这使得工厂方法模式可以允许系统在不修改工厂角色的情况下引进新产品。 工厂方法模式的主要优点是增加新的产品类时无须修改现有系统，并封装了产品对象的创建细节，系统具有良好的灵活性和可扩展性；其缺点在于增加新产品的同时需要增加新的工厂，导致系统类的个数成对增加，在一定程度上增加了系统的复杂性。 工厂方法模式适用情况包括：一个类不知道它所需要的对象的类；一个类通过其子类来指定创建哪个对象；将创建对象的任务委托给多个工厂子类中的某一个，客户端在使用时可以无须关心是哪一个工厂子类创建产品子类，需要时再动态指定。]]></content>
      <categories>
        <category>软件编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式之状态模式]]></title>
    <url>%2Fblogs%2F1603223013.html</url>
    <content type="text"><![CDATA[一、模式动机在很多情况下，一个对象的行为取决于一个或多个动态变化的属性，这样的属性叫做状态，这样的对象叫做有状态的(stateful)对象，这样的对象状态是从事先定义好的一系列值中取出的。当一个这样的对象与外部事件产生互动时，其内部状态就会改变，从而使得系统的行为也随之发生变化。 二、模式定义 状态模式(State Pattern)：允许一个对象在其内部状态改变时改变它的行为，对象看起来似乎修改了它的类。其别名为状态对象(Objects for States)，状态模式是一种对象行为型模式。 三、模式结构1. 角色组成：状态模式包含如下角色： Context: 环境类 State: 抽象状态角色 ConcreteState: 具体状态角色类 2. 结构图： 3. 时序图： 四、示例代码首先，是抽象的状态角色接口： /** * 抽象状态角色 * Created by blinkfox on 16/7/12. */ public interface IState { /** * 抽象方法1 */ void handle1(); /** * 抽象方法2 */ void handle2(); } 接下来，是多个具体的状态角色类，分别如下： /** * 具体状态角色类1 * Created by blinkfox on 16/7/12. */ public class ConcreteState1 implements IState { /** * 具体状态角色类1中的方法1 */ @Override public void handle1() { System.out.println("执行了具体状态角色类1中的方法1..."); } /** * 具体状态角色类1中的方法2 */ @Override public void handle2() { System.out.println("执行了具体状态角色类1中的方法2..."); } } /** * 具体状态角色类2 * Created by blinkfox on 16/7/12. */ public class ConcreteState2 implements IState { /** * 具体状态角色类2中的方法1 */ @Override public void handle1() { System.out.println("执行了具体状态角色类2中的方法1..."); } /** * 具体状态角色类2中的方法2 */ @Override public void handle2() { System.out.println("执行了具体状态角色类2中的方法2..."); } } 然后，是环境类： /** * 环境角色类 * Created by blinkfox on 16/7/12. */ public class Context { // 当前状态 private IState state; /** * 构造方法 * @param state */ public Context(IState state) { this.state = state; } /** * 方法1 */ public void handle1() { this.state.handle1(); } /** * 方法2 */ public void handle2() { this.state.handle2(); } } 最后，是用于测试状态模式的客户端场景类： /** * 状态模式的客户端场景累 * Created by blinkfox on 16/7/12. */ public class StateClient { public static void main(String[] args) { Context context = new Context(new ConcreteState1()); context.handle1(); context.handle2(); } } 五、模式分析 状态模式描述了对象状态的变化以及对象如何在每一种状态下表现出不同的行为。 状态模式的关键是引入了一个抽象接口来专门表示对象的状态，这个类我们叫做抽象状态接口，而对象的每一种具体状态类都实现了该类，并在不同具体状态类中实现了不同状态的行为，包括各种状态之间的转换。 在状态模式结构中需要理解环境类与抽象状态类的作用： 环境类实际上就是拥有状态的对象，环境类有时候可以充当状态管理器(State Manager)的角色，可以在环境类中对状态进行切换操作。 抽象状态类可以是抽象类，也可以是接口，不同状态类就是继承这个父类的不同子类，状态类的产生是由于环境类存在多个状态，同时还满足两个条件： 这些状态经常需要切换，在不同的状态下对象的行为不同。因此可以将不同对象下的行为单独提取出来封装在具体的状态类中，使得环境类对象在其内部状态改变时可以改变它的行为，对象看起来似乎修改了它的类，而实际上是由于切换到不同的具体状态类实现的。由于环境类可以设置为任一具体状态类，因此它针对抽象状态类进行编程，在程序运行时可以将任一具体状态类的对象设置到环境类中，从而使得环境类可以改变内部状态，并且改变行为。 1. 优点状态模式的优点： 封装了转换规则。 枚举可能的状态，在枚举状态之前需要确定状态种类。 将所有与某个状态有关的行为放到一个类中，并且可以方便地增加新的状态，只需要改变对象状态即可改变对象的行为。 允许状态转换逻辑与状态对象合成一体，而不是某一个巨大的条件语句块。 可以让多个环境对象共享一个状态对象，从而减少系统中对象的个数。 2. 缺点状态模式的缺点： 状态模式的使用必然会增加系统类和对象的个数。 状态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱。 状态模式对“开闭原则”的支持并不太好，对于可以切换状态的状态模式，增加新的状态类需要修改那些负责状态转换的源代码，否则无法切换到新增状态；而且修改某个状态类的行为也需修改对应类的源代码。 3.适用环境在以下情况下可以使用状态模式： 对象的行为依赖于它的状态（属性）并且可以根据它的状态改变而改变它的相关行为。 代码中包含大量与对象状态有关的条件语句，这些条件语句的出现，会导致代码的可维护性和灵活性变差，不能方便地增加和删除状态，使客户类与类库之间的耦合增强。在这些条件语句中包含了对象的行为，而且这些条件对应于对象的各种状态。 状态模式在工作流或游戏等类型的软件中得以广泛使用，甚至可以用于这些系统的核心功能设计，如在政府OA办公系统中，一个批文的状态有多种：尚未办理；正在办理；正在批示；正在审核；已经完成等各种状态，而且批文状态不同时对批文的操作也有所差异。使用状态模式可以描述工作流对象（如批文）的状态转换以及不同状态下它所具有的行为。 六、总结 状态模式允许一个对象在其内部状态改变时改变它的行为，对象看起来似乎修改了它的类。其别名为状态对象，状态模式是一种对象行为型模式。 状态模式包含三个角色：环境类又称为上下文类，它是拥有状态的对象，在环境类中维护一个抽象状态类State的实例，这个实例定义当前状态，在具体实现时，它是一个State子类的对象，可以定义初始状态；抽象状态类用于定义一个接口以封装与环境类的一个特定状态相关的行为；具体状态类是抽象状态类的子类，每一个子类实现一个与环境类的一个状态相关的行为，每一个具体状态类对应环境的一个具体状态，不同的具体状态类其行为有所不同。 状态模式描述了对象状态的变化以及对象如何在每一种状态下表现出不同的行为。 状态模式的主要优点在于封装了转换规则，并枚举可能的状态，它将所有与某个状态有关的行为放到一个类中，并且可以方便地增加新的状态，只需要改变对象状态即可改变对象的行为，还可以让多个环境对象共享一个状态对象，从而减少系统中对象的个数；其缺点在于使用状态模式会增加系统类和对象的个数，且状态模式的结构与实现都较为复杂，如果使用不当将导致程序结构和代码的混乱，对于可以切换状态的状态模式不满足“开闭原则”的要求。 状态模式适用情况包括：对象的行为依赖于它的状态（属性）并且可以根据它的状态改变而改变它的相关行为；代码中包含大量与对象状态有关的条件语句，这些条件语句的出现，会导致代码的可维护性和灵活性变差，不能方便地增加和删除状态，使客户类与类库之间的耦合增强。]]></content>
      <categories>
        <category>软件编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式之策略模式]]></title>
    <url>%2Fblogs%2F2812777186.html</url>
    <content type="text"><![CDATA[一、模式动机完成一项任务，往往可以有多种不同的方式，每一种方式称为一个策略，我们可以根据环境或者条件的不同选择不同的策略来完成该项任务。在软件开发中也常常遇到类似的情况，实现某一个功能有多个途径，此时可以使用一种设计模式来使得系统可以灵活地选择解决途径，也能够方便地增加新的解决途径。 在软件系统中，有许多算法可以实现某一功能，如查找、排序等，一种常用的方法是硬编码(Hard Coding)在一个类中，如需要提供多种查找算法，可以将这些算法写到一个类中，在该类中提供多个方法，每一个方法对应一个具体的查找算法；当然也可以将这些查找算法封装在一个统一的方法中，通过if…else…等条件判断语句来进行选择。这两种实现方法我们都可以称之为硬编码，如果需要增加一种新的查找算法，需要修改封装算法类的源代码；更换查找算法，也需要修改客户端调用代码。在这个算法类中封装了大量查找算法，该类代码将较复杂，维护较为困难。 除了提供专门的查找算法类之外，还可以在客户端程序中直接包含算法代码，这种做法更不可取，将导致客户端程序庞大而且难以维护，如果存在大量可供选择的算法时问题将变得更加严重。 为了解决这些问题，可以定义一些独立的类来封装不同的算法，每一个类封装一个具体的算法，在这里，每一个封装算法的类我们都可以称之为策略(Strategy)，为了保证这些策略的一致性，一般会用一个抽象的策略类来做算法的定义，而具体每种算法则对应于一个具体策略类。 二、模式定义 策略模式(Strategy Pattern)：定义一系列算法，将每一个算法封装起来，并让它们可以相互替换。策略模式让算法独立于使用它的客户而变化，也称为政策模式(Policy)。 策略模式是一种对象行为型模式。 三、 模式结构策略模式包含如下角色： Context: 环境类 Strategy: 抽象策略类 ConcreteStrategy: 具体策略类 结构图 时序图 四、示例代码首先定义一个策略接口： public interface IStrategy { /** * 策略模式的运算法则 */ public void doSomething(); } 然后是具体的策略实现类： public class ConcreteStrategy1 implements IStrategy { @Override public void doSomething() { System.out.println("具体策略的策略方法1"); } } public class ConcreteStrategy2 implements IStrategy { @Override public void doSomething() { System.out.println("具体策略的策略方法2"); } } 接着是封装角色的类： public class Context { // 抽象策略 private IStrategy strategy; /** * 构造函数设置具体策略 * @param strategy */ public Context(IStrategy strategy) { this.strategy = strategy; } /** * 封装后的策略方法 */ public void doAnything() { this.strategy.doSomething(); } } 最后是客户端的调用策略类： public class Client { public static void main(String[] args) { // 声明一个具体的策略 IStrategy strategy = new ConcreteStrategy1(); // 声明上下文对象 Context context = new Context(strategy); // 执行封装后的方法 context.doAnything(); } } 五、模式分析总体分析 策略模式是一个比较容易理解和使用的设计模式，策略模式是对算法的封装，它把算法的责任和算法本身分割开，委派给不同的对象管理。策略模式通常把一个系列的算法封装到一系列的策略类里面，作为一个抽象策略类的子类。用一句话来说，就是“准备一组算法，并将每一个算法封装起来，使得它们可以互换”。 在策略模式中，应当由客户端自己决定在什么情况下使用什么具体策略角色。 策略模式仅仅封装算法，提供新算法插入到已有系统中，以及老算法从系统中“退休”的方便，策略模式并不决定在何时使用何种算法，算法的选择由客户端来决定。这在一定程度上提高了系统的灵活性，但是客户端需要理解所有具体策略类之间的区别，以便选择合适的算法，这也是策略模式的缺点之一，在一定程度上增加了客户端的使用难度。 优点策略模式的优点： 策略模式提供了对“开闭原则”的完美支持，用户可以在不修改原有系统的基- 础上选择算法或行为，也可以灵活地增加新的算法或行为。 策略模式提供了管理相关的算法族的办法。 策略模式提供了可以替换继承关系的办法。 使用策略模式可以避免使用多重条件转移语句。 缺点策略模式的缺点： 客户端必须知道所有的策略类，并自行决定使用哪一个策略类。 策略模式将造成产生很多策略类，可以通过使用享元模式在一定程度上减少对象的数量。 适用环境在以下情况下可以使用策略模式： 如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 一个系统需要动态地在几种算法中选择一种。 如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。 不希望客户端知道复杂的、与算法相关的数据结构，在具体策略类中封装算法和相关的数据结构，提高算法的保密性与安全性。 模式扩展策略模式与状态模式： 可以通过环境类状态的个数来决定是使用策略模式还是状态模式。 策略模式的环境类自己选择一个具体策略类，具体策略类无须关心环境类；而状态模式的环境类由于外在因素需要放进一个具体状态中，以便通过其方法实现状态的切换，因此环境类和状态类之间存在一种双向的关联关系。 使用策略模式时，客户端需要知道所选的具体策略是哪一个，而使用状态模式时，客户端无须关心具体状态，环境类的状态会根据用户的操作自动转换。 如果系统中某个类的对象存在多种状态，不同状态下行为有差异，而且这些状态之间可以发生转换时使用状态模式；如果系统中某个类的某一行为存在多种实现方式，而且这些实现方式可以互换时使用策略模式。 六、总结 在策略模式中定义了一系列算法，将每一个算法封装起来，并让它们可以相互替换。策略模式让算法独立于使用它的客户而变化，也称为政策模式。策略模式是一种对象行为型模式。 策略模式包含三个角色：环境类在解决某个问题时可以采用多种策略，在环境类中维护一个对抽象策略类的引用实例；抽象策略类为所支持的算法声明了抽象方法，是所有策略类的父类；具体策略类实现了在抽象策略类中定义的算法。 策略模式是对算法的封装，它把算法的责任和算法本身分割开，委派给不同的对象管理。策略模式通常把一个系列的算法封装到一系列的策略类里面，作为一个抽象策略类的子类。 策略模式主要优点在于对“开闭原则”的完美支持，在不修改原有系统的基础上可以更换算法或者增加新的算法，它很好地管理算法族，提高了代码的复用性，是一种替换继承，避免多重条件转移语句的实现方式；其缺点在于客户端必须知道所有的策略类，并理解其区别，同时在一定程度上增加了系统中类的个数，可能会存在很多策略类。 策略模式适用情况包括：在一个系统里面有许多类，它们之间的区别仅在于它们的行为，使用策略模式可以动态地让一个对象在许多行为中选择一种行为；一个系统需要动态地在几种算法中选择一种；避免使用难以维护的多重条件选择语句；希望在具体策略类中封装算法和与相关的数据结构。]]></content>
      <categories>
        <category>软件编程</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 常用命令]]></title>
    <url>%2Fblogs%2F2172419459.html</url>
    <content type="text"><![CDATA[Linux连接工具在项目开发过程中，所用到的服务器基本上都是linux服务器，所以掌握一些linux命令是十分必要的。推荐两款很好用的工具： Xshell：Linux命令控制台。 Xftp：最主要的是上传下载，我还可以用他来创建文件夹，创建文件，修改文件，删除文件等等。。 下面是linux的基本结构目录： ##Linux常用 ls命令就是list的缩写，通过ls 命令不仅可以查看linux文件夹包含的文件，而且可以查看文件权限(包括目录、文件夹、文件权限)查看目录信息等等。。常用参数搭配： ls -a 列出目录所有文件，包含以.开始的隐藏文件 ls -A 列出除.及..的其它文件 ls -r 反序排列 ls -t 以文件修改时间排序 ls -S 以文件大小排序 ls -h 以易读大小显示 ls -l 除了文件名之外，还将文件的权限、所有者、文件大小等信息详细列出来实例： ls -lhrt 按易读方式按时间反序排序，并显示文件详细信息 ls -lrS 按大小反序显示文件详细信息 ls -l t* 列出当前目录中所有以“t”开头的目录的详细内容 ls | sed &quot;s:^:pwd/:&quot; 列出文件绝对路径（不包含隐藏文件） find $pwd -maxdepth 1 | xargs ls -ld 列出文件绝对路径（包含隐藏文件） cd命令(changeDirectory),命令语法：cd [目录名]。说明：切换当前目录至dirName cd var 切换到var目录 cd .. 切换到上一层目录 cd / 切换到系统根目录 cd ~ 切换到用户主目录 pwd命令： pwd 查看当前路径 pwd -P 查看软链接的实际路径 mkdir命令：创建文件夹 -&gt;&gt;常用参数 -m: 对新建目录设置存取权限,也可以用chmod命令设置;-p: 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那 些尚不在的目录,即一次可以建立多个目录; -&gt;&gt;实例 mkdir name 当前工作目录下创建名为name的文件夹mkdir -p /tmp/test/t1/t 在tmp目录下创建路径为test/t1/t的目录，若不存在，则创建。 这两个操作直接在xftp工具中鼠标点击也能实现。 rm命令删除一个目录中的一个或多个文件或目录，如果没有使用- r选项，则rm不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状rm [选项] 文件… rm -i *.log 删除任何.log文件，删除前逐一询问确认 rm -rf test 删除test子目录及子目录中所有档案删除,并且不用一一确认 rm -- -f* 删除以-f开头的文件 rmdir命令从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对其父目录的写权限。注意：不能删除非空目录 rmdir -p parent/child/child11 当parent子目录被删除后使它也成为空目录的话，则顺便一并删除 mv命令移动文件或修改文件名，根据第二参数类型（如目录，则移动文件；如为文件则重命令该文件）。当第二个参数为目录时，可刚多个文件以空格分隔作为第一参数，移动多个文件到参数2指定的目录中 mv test.log test1.txt 将文件test.log重命名为test1.txt mv llog1.txt log2.txt log3.txt /test3 将文件log1.txt,log2.txt,log3.txt移动到根的test3目录中 mv -i log1.txt log2.txt 将文件file1改名为file2，如果file2已经存在，则询问是否覆盖 mv * ../移动当前文件夹下的所有文件到上一级目录 cp命令将源文件复制至目标文件，或将多个源文件复制至目标目录。注意：命令行复制，如果目标文件已经存在会提示是否覆盖，而在shell脚本中，如果不加-i参数，则不会提示，而是直接覆盖！ -&gt;&gt;常用参数 -i 提示-r 复制目录及目录内所有项目-a 复制的文件与原文件时间一样 -&gt;&gt;实例 cp -ai a.txt test 复制a.txt到test目录下，保持原文件时间,如果原文件存在提示是否覆盖 cp -s a.txt link_a.txt 为a.txt建议一个链接（快捷方式） cat命令 cat主要有三大功能： 一次显示整个文件:cat filename 从键盘创建一个文件:cat &gt; filename 只能创建新文件,不能编辑已有文件. 将几个文件合并为一个文件:cat file1 file2 &gt; file -&gt;&gt;常用参数 -b 对非空输出行号-n 输出所有行号 -&gt;&gt;实例 cat -n log2012.log log2013.log 把 log2012.log 的文件内容加上行号后输入 log2013.log 这个文件里 cat -b log2012.log log2013.log log.log把 log2012.log 和 log2013.log 的文件内容加上行号（空白行不加）之后将内容附加到 log.log 里 less命令less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。 -&gt;&gt;常用命令参数 -i 忽略搜索时的大小写 -N 显示每行的行号 -o &lt;文件名&gt; 将less 输出的内容在指定文件中保存起来 -s 显示连续空行为一行 /字符串：向下搜索“字符串”的功能 ?字符串：向上搜索“字符串”的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） -x &lt;数字&gt; 将“tab”键显示为规定的数字空格 b 向后翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 -&gt;&gt;实例： ps -aux | less -N ps查看进程信息并通过less分页显示 less 1.log 2.log 可以使用n查看下一个，使用p查看前一个 more命令功能类似于cat, more会以一页一页的显示方便使用者逐页阅读，而最基本的指令就是按空白键（space）就往下一页显示，按 b 键就会往回（back）一页显示 -&gt;&gt;命令参数： +n 从笫n行开始显示 -n 定义屏幕大小为n行 +/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示 -d 提示“Press space to continue，’q’ to quit（按空格键继续，按q键退出）”，禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 -&gt;&gt;常用操作命令： Enter 向下n行，需要定义。默认为1行 Ctrl+F 向下滚动一屏 空格键 向下滚动一屏 Ctrl+B 返回上一屏 = 输出当前行的行号 :f 输出文件名和当前行的行号 V 调用vi编辑器 !命令 调用Shell，并执行命令 q 退出more -&gt;&gt;实例： more +3 text.txt 显示文件中从第3行起的内容 ls -l | more -5 在所列出文件目录详细信息，借助管道使每次显示5行，按空格显示下5行 tail命令用于显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。 -&gt;&gt;常用参数： -f 循环读取（常用于查看递增的日志文件） -n&lt;行数&gt; 显示行数（从后向前） -&gt;&gt;实例： tail -f ping.log 查看日志 find命令用于在文件树中查找文件，并作出相应的处理 -&gt;&gt;命令格式 find pathname -options [-print -exec -ok ...] -&gt;&gt;命令参数： pathname: find命令所查找的目录路径。例如用.来表示当前目录，用/来表示系统根目录。 -print： find命令将匹配的文件输出到标准输出。 -exec： find命令对匹配的文件执行该参数所给出的shell命令。相应命令的形式为’command’ { } \;，注意{ }和\；之间的空格。 -ok： 和-exec的作用相同，只不过以一种更为安全的模式来执行该参数所给出的shell命令，在执行每一个命令之前，都会给出提示，让用户来确定是否执行。 -&gt;&gt;命令选项： -name 按照文件名查找文件 -perm 按文件权限查找文件 -user 按文件属主查找文件 -group 按照文件所属的组来查找文件。 -type 查找某一类型的文件，诸如： b - 块设备文件 d - 目录 c - 字符设备文件 l - 符号链接文件 p - 管道文件 f - 普通文件 -size n :[c] 查找文件长度为n块文件，带有c时表文件字节大小 -amin n 查找系统中最后N分钟访问的文件 -atime n 查找系统中最后n*24小时访问的文件 -cmin n 查找系统中最后N分钟被改变文件状态的文件 -ctime n 查找系统中最后n*24小时被改变文件状态的文件 -mmin n 查找系统中最后N分钟被改变文件数据的文件 -mtime n 查找系统中最后n*24小时被改变文件数据的文件(用减号-来限定更改时间在距今n日以内的文件，而用加号+来限定更改时间在距今n日以前的文件。 ) -maxdepth n 最大查找目录深度 -prune 选项来指出需要忽略的目录。在使用-prune选项时要当心，因为如果你同时使用了-depth选项，那么-prune选项就会被find命令忽略 -newer 如果希望查找更改时间比某个文件新但比另一个文件旧的所有文件，可以使用-newer选项 -&gt;&gt;实例： find -atime -2 查找48小时内修改过的文件 find ./ -name &#39;*.log&#39; 在当前目录查找 以.log结尾的文件。 “. “代表当前目录 find /opt -perm 777 查找/opt目录下 权限为 777的文件 find -size +1000c 查找大于1K的文件 find -size 1000c 查找等于1000字符的文件 -exec 参数后面跟的是command命令，它的终止是以;为结束标志的，所以这句命令后面的分号是不可缺少的，考虑到各个系统中分号会有不同的意义，所以前面加反斜杠。{} 花括号代表前面find查找出来的文件名。 -&gt;&gt;实例： find . -type f -mtime +10 -exec rm -f {} \ 在当前目录中查找更改时间在10日以前的文件并删除它们(无提醒） find . -name &#39;*.log&#39; mtime +5 -ok -exec rm {} \ 当前目录中查找所有文件名以.log结尾、更改时间在5日以上的文件，并删除它们，只不过在删除之前先给出提示。 按y键删除文件，按n键不删除 find . -f -name &#39;passwd*&#39; -exec grep &quot;pkg&quot; {} \ 当前目录下查找文件名以passwd开头，内容包含”pkg”字符的文件 find . -name &#39;*.log&#39; -exec cp {} test3 \ 用exec选项执行cp命令 -xargs find 命令把匹配到的文件传递给xargs命令，而xargs命令每次只获取一部分文件而不是全部，不像-exec选项那样。这样它可以先处理最先获取的一部分文件，然后是下一批，并如此继续下去。 -&gt;&gt;实例： find . -type f -print | xargs file查找当前目录下每个普通文件，然后使用xargs来判断文件类型 find . -type f -name &quot;*.js&quot; -exec grep -lF &#39;ueditor&#39; {} \查找当前目录下所有以js结尾的并且其中包含’editor’字符的普通文件 find -type f -name &#39;*.js&#39; | xargs grep -lF &#39;editor&#39; find . -name &quot;*.log&quot; | xargs -i mv {} test4利用xargs执行mv命令 find . -name \*(转义） -type f -print | xargs grep -n &#39;hostnames&#39;用grep命令在当前目录下的所有普通文件中搜索hostnames这个词,并标出所在行 find . -name &#39;[a-z]*[4-9].log&#39; -print查找当前目录中以一个小写字母开头，最后是4到9加上.log结束的文件 find test -path &#39;test/test4&#39; -prune -o -print在test目录查找不在test4子目录查找 find -newer log2012.log ! -newer log2017.log实例1：查找更改时间比文件log2012.log新但比文件log2017.log旧的文件 使用depth选项：depth选项可以使find命令向磁带上备份文件系统时，希望首先备份所有的文件，其次再备份子目录中的文件。 -&gt;&gt;实例： find / -name &quot;CON.FILE&quot; -depth -print find命令从文件系统的根目录开始，查找一个名为CON.FILE的文件。 它将首先匹配所有的文件然后再进入子目录中查找 tar命令用来压缩和解压文件。tar本身不具有压缩功能，只具有打包功能，有关压缩及解压是调用其它的功能来完成。 弄清两个概念：打包和压缩。打包是指将一大堆文件或目录变成一个总的文件；压缩则是将一个大的文件通过一些压缩算法变成一个小文件 -&gt;&gt;常用参数： -c 建立新的压缩文件 -f 指定压缩文件 -r 添加文件到已经压缩文件包中 -u 添加改了和现有的文件到压缩包中 -x 从压缩包中抽取文件 -t 显示压缩文件中的内容 -z 支持gzip压缩 -j 支持bzip2压缩 -Z 支持compress解压文件 -v 显示操作过程 有关gzip及bzip2压缩 gzip实例： gzip fileName .tar.gz 压缩 gunzip filename.gz或gzip -d filename.gz 解压 对应： tar zcvf filename.tar.gz 压缩 tar zxvf filename.tar.gz 解压 bz2实例： bzip2 -z filename .tar.bz2 压缩 bunzip filename.bz2或bzip -d filename.bz2 解压 对应： tar jcvf filename.tar.gz 压缩 tar jxvf filename.tar.bz2 解压： -&gt;&gt;实例： tar -cvf log.tar 1.log,2.log 或tar -cvf log.* 将文件全部打包成tar包 tar -zcvf /tmp/etc.tar.gz /etc 将/etc下的所有文件及目录打包到指定目录，并使用gz压缩 tar -ztvf /tmp/etc.tar.gz 查看刚打包的文件内容（一定加z，因为是使用gzip压缩的） tar --exclude /home/dmtsai -zcvf myfile.tar.gz /home/* /etc 要压缩打包/home, /etc ，但不要 /home/dmtsai grep命令强大的文本搜索命令，grep(Global Regular Expression Print)全局正则表达式搜索 grep的工作方式是这样的，它在一个或多个文件中搜索字符串模板。如果模板包括空格，则必须被引用，模板后的所有字符串被看作文件名。搜索的结果被送到标准输出，不影响原文件内容。 -&gt;&gt;命令格式 grep [option] pattern file|dir -&gt;&gt;常用参数： -A n --after-context 显示匹配字符后n行 -B n --before-context 显示匹配字符前n行 -C n --context 显示匹配字符前后n行 -c --count 计算符合样式的列数 -i 忽略大小写 -l 只列出文件内容符合指定的样式的文件名称 -f 从文件中读取关键词 -n 显示匹配内容的所在文件中行数 -R 递归查找文件夹 grep的规则表达式: ^ 锚定行的开始 如：’^grep’匹配所有以grep开头的行。$ 锚定行的结束 如：’grep$’匹配所有以grep结尾的行。. 匹配一个非换行符的字符 如：’gr.p’匹配gr后接一个任意字符，然后是p。* 匹配零个或多个先前字符 如：’grep’匹配所有一个或多个空格后紧跟grep的行。`.一起用代表任意字符。[]匹配一个指定范围内的字符，如&#39;[Gg]rep&#39;匹配Grep和grep。[^]匹配一个不在指定范围内的字符，如：&#39;[^A-FH-Z]rep&#39;匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。(..)标记匹配字符，如&#39;\(love\)&#39;，love被标记为1。\&lt;锚定单词的开始，如:&#39;\&lt;grep&#39;匹配包含以grep开头的单词的行。>锚定单词的结束，如&#39;grep\&gt;&#39;匹配包含以grep结尾的单词的行。x{m}重复字符x，m次，如：&#39;0\{5\}&#39;匹配包含5个o的行。x{m,}重复字符x,至少m次，如：&#39;o\{5,\}&#39;匹配至少有5个o的行。x{m,n}重复字符x，至少m次，不多于n次，如：&#39;o\{5,10\}&#39;匹配5--10个o的行。\w匹配文字和数字字符，也就是[A-Za-z0-9]，如：&#39;G\w*p&#39;匹配以G后跟零个或多个文字或数字字符，然后是p。\W\w的反置形式，匹配一个或多个非单词字符，如点号句号等。\b` 单词锁定符，如: ‘\bgrep\b’只匹配grep。 -&gt;&gt;实例： ps -ef | grep svn 查找指定进程 ps -ef | grep svn -c 查找指定进程个数 cat test1.txt | grep -f key.log 从文件中读取关键词 grep -lR &#39;^grep&#39; /tmp 从文件夹中递归查找以grep开头的行，并只列出文件 grep &#39;^[^x]&#39; test.txt 查找非x开关的行内容 grep -E &#39;ed|at&#39; test.txt 显示包含ed或者at字符的内容行 ps命令ps(process status)，用来查看当前运行的进程状态，一次性查看，如果需要动态连续结果使用top linux上进程有5种状态: 运行(正在运行或在运行队列中等待) 中断(休眠中, 受阻, 在等待某个条件的形成或接受到信号) 不可中断(收到信号不唤醒和不可运行, 进程必须等待直到有中断发生) 僵死(进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放) 停止(进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行) ps工具标识进程的5种状态码: D 不可中断 uninterruptible sleep (usually IO)R 运行 runnable (on run queue)S 中断 sleepingT 停止 traced or stoppedZ 僵死 a defunct (”zombie”) process -&gt;&gt;命令参数： -A 显示所有进程 a 显示所有进程 -a 显示同一终端下所有进程 c 显示进程真实名称 e 显示环境变量 f 显示进程间的关系 r 显示当前终端运行的进程 -aux 显示所有包含其它使用的进程 -&gt;&gt;实例： ps -ef 显示当前所有进程环境变量及进程间关系 ps -A 显示当前所有进程 ps -aux | grep apache 与grep联用查找某进程 ps aux | grep &#39;(cron|syslog)&#39; 找出与 cron 与 syslog 这两个服务有关的 PID 号码 kill命令发送指定的信号到相应进程。不指定型号将发送SIGTERM（15）终止指定进程。如果任无法终止该程序可用“-KILL” 参数，其发送的信号为SIGKILL(9) ，将强制结束进程，使用ps命令或者jobs 命令可以查看进程号。root用户将影响用户的进程，非root用户只能影响自己的进程。 -&gt;&gt;常用参数： -l 信号，若果不加信号的编号参数，则使用“-l”参数会列出全部的信号名称 -a 当处理当前进程时，不限制命令名和进程号的对应关系 -p 指定kill 命令只打印相关进程的进程号，而不发送任何信号 -s 指定发送信号 -u 指定用户 -&gt;&gt;实例： kill -9 $(ps -ef | grep pro1) 先使用ps查找进程pro1，然后用kill杀掉 其他命令head命令head 用来显示档案的开头至标准输出中，默认head命令打印其相应文件的开头10行。 -&gt;&gt;常用参数： -n&lt;行数&gt; 显示的行数（行数为复数表示从最后向前数） -&gt;&gt;实例： head 1.log -n 20 显示1.log文件中前20行 head -c 20 log2014.log 显示1.log文件前20字节 head -n -10 t.log显示t.log最后10行 which命令 在linux要查找某个文件，但不知道放在哪里了，可以使用下面的一些命令来搜索： which 查看可执行文件的位置。 whereis 查看文件的位置。 locate 配合数据库查看文件位置。 find 实际搜寻硬盘查询文件名称。 which是在PATH就是指定的路径中，搜索某个系统命令的位置，并返回第一个搜索结果。使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 -&gt;&gt;常用参数： -n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名。 -&gt;&gt;实例： which ls 查看ls命令是否存在，执行哪个 which which 查看which which cd查看cd（显示不存在，因为cd是内建命令，而which查找显示是PATH中的命令）查看当前PATH配置：echo $PATH；或使用env查看所有环境变量及对应值 whereis命令whereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。whereis及locate都是基于系统内建的数据库进行搜索，因此效率很高，而find则是遍历硬盘查找文件。 -&gt;&gt;常用参数： -b 定位可执行文件。 -m 定位帮助文件。 -s 定位源代码文件。 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件。 -&gt;&gt;实例： whereis locate 查找locate程序相关文件 whereis -s locate 查找locate的源码文件 whereis -m locate 查找lcoate的帮助文件 locate命令locate通过搜寻系统内建文档数据库达到快速找到档案，数据库由updatedb程序来更新，updatedb是由cron daemon周期性调用的。默认情况下locate命令在搜寻数据库时比由整个由硬盘资料来搜寻资料来得快，但较差劲的是locate所找到的档案若是最近才建立或 刚更名的，可能会找不到，在内定值中，updatedb每天会跑一次，可以由修改crontab来更新设定值。(etc/crontab)。 locate与find命令相似，可以使用如*、?等进行正则匹配查找 -&gt;&gt;常用参数： -l num（要显示的行数） -f 将特定的档案系统排除在外，如将proc排除在外 -r 使用正则运算式做为寻找条件 -&gt;&gt;实例： locate pwd查找和pwd相关的所有文件(文件名中包含pwd） locate /etc/sh 搜索etc目录下所有以sh开头的文件 locate -r &#39;^/var.*reason$&#39;（其中.表示一个字符，表示任务多个；.表示任意多个字符） 查找/var目录下，以reason结尾的文件 chmod命令用于改变linux系统文件或目录的访问权限。用它控制文件或目录的访问权限。该命令有两种用法。一种是包含字母和操作符表达式的文字设定法；另一种是包含数字的数字设定法。 每一文件或目录的访问权限都有三组，每组用三位表示，分别为文件属主的读、写和执行权限；与属主同组的用户的读、写和执行权限；系统中其他用户的读、写和执行权限。可使用ls -l test.txt查找 以文件log2012.log为例： -rw-r--r-- 1 root root 296K 11-13 06:03 log2012.log 第一列共有10个位置，第一个字符指定了文件类型。在通常意义上，一个目录也是一个文件。如果第一个字符是横线，表示是一个非目录的文件。如果是d，表示是一个目录。从第二个字符开始到第十个共9个字符，3个字符一组，分别表示了3组用户对文件或者目录的权限。权限字符用横线代表空许可，r代表只读，w代表写，x代表可执行。 -&gt;&gt;常用参数： -c 当发生改变时，报告处理信息 -R 处理指定目录以及其子目录下所有文件 权限范围： u ：目录或者文件的当前的用户 g ：目录或者文件的当前的群组 o ：除了目录或者文件的当前用户或群组之外的用户或者群组 a ：所有的用户及群组 权限代号： r ：读权限，用数字4表示 w ：写权限，用数字2表示 x ：执行权限，用数字1表示 ：删除权限，用数字0表示 s ：特殊权限 -&gt;&gt;实例： chmod a+x t.log 增加文件t.log所有用户可执行权限 chmod u=r t.log -c撤销原来所有的权限，然后使拥有者具有可读权限,并输出处理信息 chmod 751 t.log -c（或者：chmod u=rwx,g=rx,o=x t.log -c) 给file的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限 chmod u+r,g+r,o+r -R text/ -c 将test目录及其子目录所有文件添加可读权限 chown命令chown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符 -&gt;&gt;常用参数： -c 显示更改的部分的信息 -R 处理指定目录及子目录 -&gt;&gt;实例： chown -c mail:mail log2012.log 改变拥有者和群组 并显示改变信息 chown -c :mail t.log 改变文件群组 chown -cR mail: test/ 改变文件夹及子文件目录属主及属组为mail df命令 显示磁盘空间使用情况。获取硬盘被占用了多少空间，目前还剩下多少空间等信息，如果没有文件名被指定，则所有当前被挂载的文件系统的可用空间将被显示。默认情况下，磁盘空间将以 1KB 为单位进行显示，除非环境变量 POSIXLY_CORRECT 被指定，那样将以512字节为单位进行显示 -&gt;&gt;常用参数： -a 全部文件系统列表 -h 以方便阅读的方式显示信息 -i 显示inode信息 -k 区块为1024字节 -l 只显示本地磁盘 -T 列出文件系统类型 实例： df -l 显示磁盘使用情况 df -haT 以易读方式列出所有文件系统及其类型 du命令du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看 -&gt;&gt;命令格式 du [选项] [文件] -&gt;&gt;常用参数： -a 显示目录中所有文件大小 -k 以KB为单位显示文件大小 -m 以MB为单位显示文件大小 -g 以GB为单位显示文件大小 -h 以易读方式显示文件大小 -s 仅显示总计 -c或--total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和 -&gt;&gt;实例： du -h scf/ 以易读方式显示文件夹内及子文件夹大小 du -ah scf/ 以易读方式显示文件夹内所有文件大小 du -hc test/ scf/ 显示几个文件或目录各自占用磁盘空间的大小，还统计它们的总和 du -hc --max-depth=1 scf/ 输出当前目录下各个子目录所使用的空间 ln命令功能是为文件在另外一个位置建立一个同步的链接，当在不同目录需要该问题时，就不需要为每一个目录创建同样的文件，通过ln创建的链接（link）减少磁盘占用量。 链接分类：软件链接及硬链接 软链接： 软链接，以路径的形式存在。类似于Windows操作系统中的快捷方式 软链接可以 跨文件系统 ，硬链接不可以 软链接可以对一个不存在的文件名进行链接 软链接可以对目录进行链接 硬链接: 硬链接，以文件副本的形式存在。但不占用实际空间。 不允许给目录创建硬链接 硬链接只有在同一个文件系统中才能创建 需要注意：第一：ln命令会保持每一处链接文件的同步性，也就是说，不论你改动了哪一处，其它的文件都会发生相同的变化； 第二：ln的链接又分软链接和硬链接两种，软链接就是ln –s 源文件 目标文件，它只会在你选定的位置上生成一个文件的镜像，不会占用磁盘空间，硬链接 ln 源文件 目标文件，没有参数-s， 它会在你选定的位置上生成一个和源文件大小相同的文件，无论是软链接还是硬链接，文件都保持同步变化。 第三：ln指令用在链接文件或目录，如同时指定两个以上的文件或目录，且最后的目的地是一个已经存在的目录，则会把前面指定的所有文件或目录复制到该目录中。若同时指定多个文件或目录，且最后的目的地并非是一个已存在的目录，则会出现错误信息。 -&gt;&gt;常用参数： -b 删除，覆盖以前建立的链接 -s 软链接（符号链接） -v 显示详细处理过程 -&gt;&gt;实例： ln -sv source.log link.log 给文件创建软链接，并显示操作信息 ln -v source.log link1.log 给文件创建硬链接，并显示操作信息 ln -sv /opt/soft/test/test3 /opt/soft/test/test5 给目录创建软链接 date命令显示或设定系统的日期与时间 -&gt;&gt;命令参数： -d&lt;字符串&gt; 显示字符串所指的日期与时间。字符串前后必须加上双引号。 -s&lt;字符串&gt; 根据字符串来设置日期与时间。字符串前后必须加上双引号。 -u 显示GMT。 %H 小时(00-23) %I 小时(00-12) %M 分钟(以00-59来表示) %s 总秒数。起算时间为1970-01-01 00:00:00 UTC。 %S 秒(以本地的惯用法来表示) %a 星期的缩写。 %A 星期的完整名称。 %d 日期(以01-31来表示)。 %D 日期(含年月日)。 %m 月份(以01-12来表示)。 %y 年份(以00-99来表示)。 %Y 年份(以四位数来表示)。 -&gt;&gt;实例： date +%Y%m%d --date=&quot;+1 day&quot; 显示下一天 -d参数使用 date -d &quot;nov 22&quot; 今年的 11 月 22 日是星期三 date -d &#39;2 weeks&#39; 2周后的日期 date -d &#39;next monday&#39; 下周一的日期 date -d next-day +%Y%m%d 或 date -d tomorrow +%Y%m%d 明天的日期 date -d last-day +%Y%m%d 或 date -d yesterday +%Y%m%d 昨天的日期 date -d last-month +%Y%m 上个月是几月 date -d next-month +%Y%m 下个月是几月 cal命令可以用户显示公历（阳历）日历如只有一个参数，则表示年份(1-9999)，如有两个参数，则表示月份和年份 -&gt;&gt;常用参数： -3 显示前一月，当前月，后一月三个月的日历 -m 显示星期一为第一列 -j 显示在当前年第几天 -y [year]显示当前年[year]份的日历 -&gt;&gt;实例： cal 9 2012 显示指定年月日期 cal -y 2013 显示2013年每个月日历 cal -3m 将星期一做为第一列,显示前中后三月 wc命令wc(word count)功能为统计指定的文件中字节数、字数、行数，并将统计结果输出 -&gt;&gt;命令格式： wc [option] file.. -&gt;&gt;命令参数： -c 统计字节数 -l 统计行数 -m 统计字符数 -w 统计词数，一个字被定义为由空白、跳格或换行字符分隔的字符串 -&gt;&gt;实例： wc text.txt 查找文件的 行数 单词数 字节数 文件名结果：7 8 70 test.txt cat test.txt | wc -l 统计输出结果的行数 top命令显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 常用参数： -c 显示完整的进程命令 -s 保密模式 -p &lt;进程号&gt; 指定进程显示 -n &lt;次数&gt;循环显示次数 -&gt;&gt;实例： top - 14:06:23 up 70 days, 16:44, 2 users, load average: 1.25, 1.32, 1.35 Tasks: 206 total, 1 running, 205 sleeping, 0 stopped, 0 zombie Cpu(s): 5.9%us, 3.4%sy, 0.0%ni, 90.4%id, 0.0%wa, 0.0%hi, 0.2%si, 0.0%st Mem: 32949016k total, 14411180k used, 18537836k free, 169884k buffers Swap: 32764556k total, 0k used, 32764556k free, 3612636k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 28894 root 22 0 1501m 405m 10m S 52.2 1.3 2534:16 java 前五行是当前系统情况整体的统计信息区: 第一行，任务队列信息，同 uptime 命令的执行结果，具体参数说明情况如下： 14:06:23 — 当前系统时间up 70 days, 16:44 — 系统已经运行了70天16小时44分钟（在这期间系统没有重启过的吆！）2 users — 当前有2个用户登录系统load average: 1.15, 1.42, 1.44 — load average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。 第二行，Tasks — 任务（进程），具体信息说明如下： 系统现在共有206个进程，其中处于运行中的有1个，205个在休眠（sleep），stoped状态的有0个，zombie状态（僵尸）的有0个。 第三行，cpu状态信息，具体属性说明如下： 5.9%us — 用户空间占用CPU的百分比。3.4% sy — 内核空间占用CPU的百分比。0.0% ni — 改变过优先级的进程占用CPU的百分比90.4% id — 空闲CPU百分比0.0% wa — IO等待占用CPU的百分比0.0% hi — 硬中断（Hardware IRQ）占用CPU的百分比0.2% si — 软中断（Software Interrupts）占用CPU的百分比备注：在这里CPU的使用比率和windows概念不同，需要理解linux系统用户空间和内核空间的相关知识！ 第四行,内存状态，具体信息如下： 32949016k total — 物理内存总量（32GB）14411180k used — 使用中的内存总量（14GB）18537836k free — 空闲内存总量（18GB）169884k buffers — 缓存的内存量 （169M） 第五行，swap交换分区信息，具体信息说明如下： 32764556k total — 交换区总量（32GB）0k used — 使用的交换区总量（0K）32764556k free — 空闲交换区总量（32GB）3612636k cached — 缓冲的交换区总量（3.6GB） 第六行，空行。 第七行以下：各进程（任务）的状态监控，项目列信息说明如下： PID — 进程idUSER — 进程所有者PR — 进程优先级NI — nice值。负值表示高优先级，正值表示低优先级VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RESRES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATASHR — 共享内存大小，单位kbS — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程%CPU — 上次更新到现在的CPU时间占用百分比%MEM — 进程使用的物理内存百分比TIME+ — 进程使用的CPU时间总计，单位1/100秒COMMAND — 进程名称（命令名/命令行） -&gt;&gt;top交互命令 h 显示top交互命令帮助信息 c 切换显示命令名称和完整命令行 m 以内存使用率排序 P 根据CPU使用百分比大小进行排序 T 根据时间/累计时间进行排序 W 将当前设置写入~/.toprc文件中 o 或 O 改变显示项目的顺序 free命令显示系统内存使用情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。 -&gt;&gt;命令参数： -b 以Byte显示内存使用情况 -k 以kb为单位显示内存使用情况 -m 以mb为单位显示内存使用情况 -g 以gb为单位显示内存使用情况 -s&lt;间隔秒数&gt; 持续显示内存 -t 显示内存使用总合 -&gt;&gt;实例： free|free -k|free -m 显示内存使用情况 free -t 以总和的形式显示内存的使用信息 free -s 10 周期性查询内存使用情况 后记 感谢这位大佬的整合~如若不允许转载，请联系博主删除。 后续会更新常用插件安装后的命令，比如上传(rz)下载(sz)编辑(vim)等等。 eg： yum install lrzsz：同步安装rz、sz rz：从本地上传文件至服务器 sz filename：从服务器下载文件至本地]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[String字符串转Date日期]]></title>
    <url>%2Fblogs%2F451064031.html</url>
    <content type="text"><![CDATA[日期转换 今日写代码的时候，发现前端的日期格式字符串不能被后台接收。于是找出了下面这么个配置来统一处理日期格式的转换。 非BOOT方式xml配置：import java.text.SimpleDateFormat; import java.util.Date; import org.springframework.beans.propertyeditors.CustomDateEditor; import org.springframework.web.bind.WebDataBinder; import org.springframework.web.bind.annotation.InitBinder; import org.springframework.web.bind.support.WebBindingInitializer; public class CustomDateFormat implements WebBindingInitializer { /** * form表单提交 Date类型数据绑定 * @param binder * @see [类、类#方法、类#成员] */ @InitBinder public void initBinder(WebDataBinder binder) { SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss"); dateFormat.setLenient(false); binder.registerCustomEditor(Date.class, new CustomDateEditor(dateFormat, true)); } } 并在spingMVC配置文件进行配置 &lt;bean class="org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapter"> &lt;property name="webBindingInitializer"> &lt;bean class="com.spinach.core.web.CustomDateFormat"/> &lt;/property> &lt;/bean> 自定义DateConverterConfig重写convert方法实现spring提供的Converter，重写里面的convert方法：： import lombok.extern.slf4j.Slf4j; import org.springframework.core.convert.converter.Converter; import org.springframework.stereotype.Component; import java.text.DateFormat; import java.text.SimpleDateFormat; import java.util.ArrayList; import java.util.Date; import java.util.List; @Component @Slf4j public class DateConverterConfig implements Converter&lt;String, Date> { private static final List&lt;String> FORMARTS = new ArrayList&lt;>(4); static { FORMARTS.add("yyyy-MM"); FORMARTS.add("yyyy-MM-dd"); FORMARTS.add("yyyy-MM-dd HH:mm"); FORMARTS.add("yyyy-MM-dd HH:mm:ss"); } @Override public Date convert(String source) { String value = source.trim(); if ("".equals(value)) { return null; } if (source.matches("^\\d{4}-\\d{1,2}$")) { return parseDate(source, FORMARTS.get(0)); } else if (source.matches("^\\d{4}-\\d{1,2}-\\d{1,2}$")) { return parseDate(source, FORMARTS.get(1)); } else if (source.matches("^\\d{4}-\\d{1,2}-\\d{1,2} {1}\\d{1,2}:\\d{1,2}$")) { return parseDate(source, FORMARTS.get(2)); } else if (source.matches("^\\d{4}-\\d{1,2}-\\d{1,2} {1}\\d{1,2}:\\d{1,2}:\\d{1,2}$")) { return parseDate(source, FORMARTS.get(3)); } else { throw new IllegalArgumentException("Invalid boolean value '" + source + "'"); } } /** * 格式化日期 * * @param dateStr String 字符型日期 * @param format String 格式 * @return Date 日期 */ private Date parseDate(String dateStr, String format) { Date date = null; try { DateFormat dateFormat = new SimpleDateFormat(format); date = dateFormat.parse(dateStr); } catch (Exception e) { log.error("日期转换错误", e); } return date; } } 我这里是springboot项目通过@Component注解将这个类交给spring容器托管的，如果springmvc项目还需要到xml配置文件注册这个类优点很明显了：足够灵活，在静态代码块里自定义任意格式日期，在重写的方法里在配上对应的正则表达式就行，也可以做到全局统一处理。 后记 感谢这位博主的文章，若有侵权，请联系博主删除。点击去原文]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用阿里云搭配git搭建博客]]></title>
    <url>%2Fblogs%2F166738594.html</url>
    <content type="text"><![CDATA[近期在阿里云买了个学生服务器，就想着把github上的博客迁移过来。整个过程陆陆续续花了一个多星期的时间，也踩了不少坑，在此做个记录备忘。 准备工作开启端口，轻量级服务器不用手动开，默认带了三个。ECS服务器需要自己配置。开启端口如下： 1、安装git使用yum安装即可 yum install git 完成后输入git version,若显示git版本信息即安装成功。 2、安装Node.js 去官网下载https://nodejs.org/en/download/，博主是用的最新版10.15.3，请务必使用7以上的版本，不然使用hexo时会报错。 解压缩改名放到/usr/local tar xvJf node-v10.15.3-linux-x64.tar.xz 将解压的 Node.js 目录移动到 /usr/local 目录下 mv node-v10.15.3-linux-x64 /usr/local/node-v10 软链接到 /bin 目录 ln -s /usr/local/node-v10/bin/node /bin/node ln -s /usr/local/node-v10/bin/npm /bin/npm 配置环境变量将 /usr/local/node-v6/bin 目录添加到 $PATH 环境变量中可以方便地使用通过 npm 全局安装的第三方工具 echo 'export PATH=/usr/local/node-v10/bin:$PATH' >> /etc/profile 使环境变量生效 source /etc/profile 测试是否成功输入node -v和npm -v,若显示版本号，即安装成功。 3、安装Hexo 安装Hexo执行以下命令即安装Hexo： npm install -g hexo-cli 安装完成后输入hexo version，若显示版本信息则安装成功。 具体hexo教程请自行百度，百度上有详细介绍(后续再补)。 4、安装Nginx 使用 yum 来安装 Nginx yum install nginx 启动Nginx systemctl start nginx 此时访问http//(你的ip地址),看到nginx测试界面则表示启动成功。 继续输入以下命令使Nginx开机自动启动： systemctl enable nginx 配置静态服务器访问路径Nginx 需要配置静态资源的路径信息才能通过 url 正确访问到服务器上的静态资源。即是要将HEXO生成的静态资源的路径放置到Nginx的访问路径 打开 Nginx 的默认配置文件 /etc/nginx/nginx.conf ，将默认的 root /usr/share/nginx/html 修改为: root /…//public （此处可能在此配置文件的42行，即为hexo初始化的文件夹） 修改完成后保存，输入以下命令重启Nginx： nginx -s reload 此时再次访问你的IP地址，若显示上文的hexo初次运行的样子，则说明配置成功。 注意：可能会报403错误，原因是nginx没有权限访问public文件夹，修改方法有两种：1.修改public文件夹的权限，修改为777（即任何人可读可写可执行），不推荐2. 修改nginx.conf中的user（可能在第5行），改为可以访问public文件夹的用户，如root。 5、创建git环境 在云服务器上创建一个 GIT 用户，用来运行 GIT 服务 创建用户：adduser git 设置密码：passwd git 创建证书 切换到git用户：su git 创建.ssh目录：mkdir .ssh &amp;&amp; chmod 700 .ssh 然后在云服务创建authorized_keys公钥保存文件：touch .ssh/authorized_keys &amp;&amp; chmod 600 .ssh/authorized_keys tip:公钥保存文件authorized_keys是一行添加一个 创建git仓库目录创建一个名为blog的git仓库 mkdir /var/repo cd /var/repo git init --bare blog.git 配置 GIT HOOKS(钩子) vim /var/repo/blog.git/hooks/post-receive 添加以下内容，wq保存。 #!/bin/sh git --work-tree=/var/www/hexo --git-dir=/var/repo/blog.git checkout -f 设置权限 chmod +x /var/repo/blog.git/hooks/post-receive 改变 blog.git 目录的拥有者为 git 用户 chown -R git:git blog.git 创建静态文件目录并将3步骤生成的git仓库链接到静态文件目录下 创建静态文件目录（文章网页）：mkdir /var/www/hexo 链接git仓库：chown -R git:git /var/www/hexo 配置权限：chmod -R 755 /var/www/hexo 这样git仓库更新便会自动同步到hexo目录下 禁用shell登录输入以下指令vim /etc/passwd找到下面这行： git:x:1001:1001:,,,:/home/git:/bin/bash 改为： git:x:1001:1001:,,,:/home/git:/usr/bin/git-shell 这样，git用户可以正常通过ssh使用git，但无法登录shell，因为我们为git用户指定的git-shell每次一登录就自动退出。 测试当上述步骤都完成后，我们就可以测试下git服务器是否部署成功，最简单的方法便是使用clone来校验。在用户git控制台输入git clone git@服务器ip:/var/repo/blog.git，当弹出密码输入框即环境搭建成功。 6、后续 剩下的操作与使用git操作无异，提交代码至git服务器，git代码会自动推送至public目录，然后通过nginx代理即可访问自己的博客啦~ 点击 参考原文1 点击 参考原文2 感谢以上两位博主的博客，没有他们的前置我也搭不出来现在的博客。若有侵权，请联系博主删除。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
        <tag>hexo</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 多级菜单树工具]]></title>
    <url>%2Fblogs%2F1705435210.html</url>
    <content type="text"><![CDATA[关于Java中多级菜单树的处理 今天被一个菜单列表的展现折磨得不轻，自己写代码发现实在是费时费力，而且代码量太大，逻辑亟待优化，后续找到了这个代码十分简洁的工具类，说实话我只能看得懂，写不出来这种东西。在此分享给大家，避免重复造轮子的工作~ 多级树Bean这是一个基础bean： /** * 功能描述： * 【分组信息bean】 * 注意，下面的bean每个属性都为必要属性，不可缺一 * 继承此bean再添加多个属性，不会影响树结构 * 类上的三个注解为lombok插件 * * @author chihiro * @version V1.0 * @date 2019/03/06 17:35 */ @Data @NoArgsConstructor @AllArgsConstructor public class BaseTree implements Serializable { private static final long serialVersionUID = 8L; /** * 树主键 */ private String treeId; /** * 父节点id */ private String parentId; /** * 子节点集合 */ private List&lt;? extends BaseTree> childrens; } 树工具类核心工具类： /** * 功能描述： * 【多级树util】 * 核心是使用递归 * * @author chihiro * @version V1.0 * @date 2019/03/06 18:45 */ @AllArgsConstructor public class TreeToolUtil&lt;T extends BaseTree> { /** * 根节点 */ private List&lt;T> rootList; /** * 叶子节点 */ private List&lt;T> bodyList; public List&lt;T> getTree() { if (CollUtil.isNotEmpty(bodyList)) { //声明一个map，用来过滤已操作过的数据 Map&lt;String, String> map = MapUtil.newHashMap(bodyList.size()); rootList.forEach(beanTree -> getChild(beanTree, map)); return rootList; } return null; } private void getChild(T beanTree, Map&lt;String, String> map) { List&lt;BaseTree> childList = CollUtil.newArrayList(); bodyList.stream() .filter(group -> !map.containsKey(group.getTreeId())) .filter(group -> group.getParentId().equals(beanTree.getTreeId())) .forEach(group -> { map.put(group.getTreeId(), group.getParentId()); getChild(group, map); childList.add(group); }); beanTree.setChildrens(childList); } } 后记 这套代码是博主从网上找来调整为自己使用的，非博主独立构建。 若遇到其他Bug，请通过博客内联系方式找博主修复。]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客说明]]></title>
    <url>%2Fblogs%2F1523215152.html</url>
    <content type="text"><![CDATA[重点说明 本站主页背景，个人相册，以及部分文章的展示图皆为wlop大大所绘制的插画，这些插画为本人所购得，如若有侵权，请联系博主删除(ps：这些画都是被我压缩过的，没有原版图，即使下载了也当不了背景或桌面)。若想取得高清/超清插画，请去友情链接中支持原作者 博主在此发文（包括但不限于汉字、拼音、拉丁字母）均为随意敲击键盘所出，用于检验本人电脑键盘录入、屏幕显示的机械、光电性能，并不代表本人局部或全部同意、支持或者反对观点。如需要详查请直接与键盘生产厂商法人代表联系。挖井挑水无水表，不会网购无快递。 文章内容部分来源于互联网，不代表本人的任何立场；涉及到的软件来源于互联网，仅供个人下载使用，请勿用于商业用途，版权归软件开发者所有，下载后请于24小时内删除，如有真实需要请支持正版！因下载本站任何资源造成的损失，全部责任由使用者本人承担！如果你是版权方，认为本文内容对您的权益有所侵犯，请联系博主，并参照侵删联系的说明提交相应的证明材料，待博主进行严格地审查和背景调查后，情况属实的将在三天内将本文删除或修正。 博主的文章没有高度、深度和广度，只是凑字数。由于博主的水平不高（其实是个菜B），不足和错误之处在所难免，希望大家能够批评指出。 博主是利用读书、参考、引用、抄袭、复制和粘贴等多种方式打造成自己的纯镀 24k 文章，请原谅博主成为一个无耻的文档搬运工！ 博主只是一名普通的互联网从业者，不懂修电脑，不会卖电脑，不会帮你盗号，不会破解开机密码，找不回你丢失的手机等，如有这样的想法请绕道！ 博主企鹅号1608536443 博主邮箱qianxun0827@outlook.com]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
</search>
